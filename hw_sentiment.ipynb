{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw_sentiment.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "SfRgudZNE4p8",
    "zcnS2g5GE4p-",
    "mXGiUhxnE4qB",
    "41k3pje5E4qD",
    "Q0gli5RcE4qE",
    "R3wVQ5zvE4qH",
    "BWiV502zE4qI",
    "PD12-AfbE4qI",
    "qxiIeHlzE4qJ",
    "EPSxqJvuU7nY",
    "Q5TTnjiJ4-V5",
    "47XJkLFv4-V5",
    "zxrE_LdR4-V7",
    "tlPoXVwxkOW6",
    "2fvF8_t_6HKy",
    "iX4-wPZ36CQ9",
    "irwlEMoimmzq",
    "ck4WfpyQrUgs",
    "MMUUEslQ-ymc",
    "DehwZWKrTaWf",
    "HSprTVYrxJUA",
    "_W575sEC0WhT",
    "mPsEjWbeJt25",
    "uxzJdE6_9zk_"
   ],
   "machine_shape": "hm"
  },
  "interpreter": {
   "hash": "e8565501620aab79e4b3b5ff526196cdd0e893328ab762a727f20a8f71d3c77c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "ef4a007d34654e5ca79c41ee9b68a0e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_5a2cb095058141eba555ee09cd54dc37",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_41d8d04b55cb41ab8bdd29a66ebcfc6c",
       "IPY_MODEL_7e40ae05da1240eaacc15696aee51b4b",
       "IPY_MODEL_6189d115bc424bad888f484a4d202e29"
      ]
     }
    },
    "5a2cb095058141eba555ee09cd54dc37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "41d8d04b55cb41ab8bdd29a66ebcfc6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_23a84edf2e434170a18fbb7d20b9b0d8",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_70d076bfceb8438db5114c8f22365372"
     }
    },
    "7e40ae05da1240eaacc15696aee51b4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_4ea06e598be84919b76e093853b8d62a",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 231508,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 231508,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ce557dad1b5e4218827fefef3df55e92"
     }
    },
    "6189d115bc424bad888f484a4d202e29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_998792a222224ce5aab18724e34bd1a2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 232k/232k [00:00&lt;00:00, 2.68MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_652f2f6add42459db51ada269a8c5203"
     }
    },
    "23a84edf2e434170a18fbb7d20b9b0d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "70d076bfceb8438db5114c8f22365372": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "4ea06e598be84919b76e093853b8d62a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ce557dad1b5e4218827fefef3df55e92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "998792a222224ce5aab18724e34bd1a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "652f2f6add42459db51ada269a8c5203": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ee842f353f674722abbcc59c98458b9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d9f69fdba32349b5bf093f31044ab4c4",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_bfd5358bb23940d9bc5b6897c1c1b303",
       "IPY_MODEL_376e1466d12b4541a0bb2df06741a14a",
       "IPY_MODEL_9c4a0324473d4305a1f54406cbd91c8b"
      ]
     }
    },
    "d9f69fdba32349b5bf093f31044ab4c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "bfd5358bb23940d9bc5b6897c1c1b303": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_0bde278e2a014c0dab704b8fdee6bd2a",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_915234df03ae4c9db2b04fd5d6f75a8e"
     }
    },
    "376e1466d12b4541a0bb2df06741a14a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_4763ed0be807452f94473ddb98428a21",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 570,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 570,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_630b7f7df2234cb98c196f4caf28f281"
     }
    },
    "9c4a0324473d4305a1f54406cbd91c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_5abe0b0d066b41d19cb20dafd3b02139",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 570/570 [00:00&lt;00:00, 22.9kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_48700b430ab8421aab0ce8c8a8283234"
     }
    },
    "0bde278e2a014c0dab704b8fdee6bd2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "915234df03ae4c9db2b04fd5d6f75a8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "4763ed0be807452f94473ddb98428a21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "630b7f7df2234cb98c196f4caf28f281": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "5abe0b0d066b41d19cb20dafd3b02139": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "48700b430ab8421aab0ce8c8a8283234": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0806d8df1976451ca0873742920b7576": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_a8d91ebfeda046a6a9eaf9884139cb26",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_6f6a325bee1646d9ad96259ab43e74d0",
       "IPY_MODEL_2aa98d0fe827422a99c309a869a64757",
       "IPY_MODEL_125e937fad444112a69da38c5a1d4522"
      ]
     }
    },
    "a8d91ebfeda046a6a9eaf9884139cb26": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6f6a325bee1646d9ad96259ab43e74d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_e74bc431adec4c41a1e70f0e1a1444d0",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_4714d6f206ea41d5a1fe479a7ecfe992"
     }
    },
    "2aa98d0fe827422a99c309a869a64757": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_a9f88d1c46a04f8fb8fe82c27532b4e7",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 440473133,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 440473133,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_765187d1c80641cda81378c6265c35fc"
     }
    },
    "125e937fad444112a69da38c5a1d4522": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_65385a4d835d41e7a2b2b5cd4737bfab",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 440M/440M [00:08&lt;00:00, 43.6MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_4d79f43a197246758b3996ab569c0066"
     }
    },
    "e74bc431adec4c41a1e70f0e1a1444d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "4714d6f206ea41d5a1fe479a7ecfe992": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a9f88d1c46a04f8fb8fe82c27532b4e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "765187d1c80641cda81378c6265c35fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "65385a4d835d41e7a2b2b5cd4737bfab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "4d79f43a197246758b3996ab569c0066": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1k36IqixE4p1"
   },
   "source": [
    "# Sentiment analysis: Research Investigation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FrOCbgjnE4p4"
   },
   "source": [
    "__author__ = \"Shubham Chowdhary\"\n",
    "__version__ = \"Original System, XCS224u, Stanford, Spring 2021\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_pHmrYNWGbm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460805907,
     "user_tz": -330,
     "elapsed": 111341,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "5158a065-041a-4ddd-e477-5b0a676943e5"
   },
   "source": [
    "# Mount colab drive\n",
    "# import os\n",
    "#\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YB_nsgLKFhUY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460807670,
     "user_tz": -330,
     "elapsed": 1768,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "799ab890-718e-4fa4-ddf6-6a59e297e647"
   },
   "source": [
    "# verify python and gpu status\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     !pwd\n",
    "#     %cd /content/drive/MyDrive/MLDL/stanfordXCS224U/referenceRepo/cs224u\n",
    "#     !python --version\n",
    "#     !nvidia-smi"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "/content/drive/MyDrive/MLDL/stanfordXCS224U/referenceRepo/cs224u\n",
      "Python 3.7.11\n",
      "Sun Sep 12 15:33:26 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wYRxvY53XOu8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460807671,
     "user_tz": -330,
     "elapsed": 3,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# install pytorch 1.8-gpu\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # !pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrVjLXxKa1EO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460813014,
     "user_tz": -330,
     "elapsed": 5345,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "20601b21-32e6-4985-e020-44f529519105"
   },
   "source": [
    "# install transformers 4.3.3 (works only after a retart of runtime if the pytorch package is freshly installed)\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     !pip install transformers==4.3.3"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers==4.3.3\n",
      "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (4.62.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (4.6.4)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001B[K     |████████████████████████████████| 895 kB 74.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (21.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (3.0.12)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 34.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (1.15.0)\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.3.3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFifsotAkJIe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460819461,
     "user_tz": -330,
     "elapsed": 6457,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "354bee18-4997-435c-844d-f68d7ef31063"
   },
   "source": [
    "# verify python, pytorch, and tranformers package version\n",
    "import os\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    !python --version\n",
    "    !pip show torch\n",
    "    print(\"\")\n",
    "    !pip show transformers\n",
    "    print(\"\")\n",
    "    import torch\n",
    "    print(torch.cuda.get_device_name(0))"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python 3.7.11\n",
      "Name: torch\n",
      "Version: 1.9.0+cu102\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /usr/local/lib/python3.7/dist-packages\n",
      "Requires: typing-extensions\n",
      "Required-by: torchvision, torchtext, fastai\n",
      "\n",
      "Name: transformers\n",
      "Version: 4.3.3\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Sylvain Gugger, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: /usr/local/lib/python3.7/dist-packages\n",
      "Requires: filelock, requests, regex, tqdm, packaging, sacremoses, numpy, tokenizers, importlib-metadata\n",
      "Required-by: \n",
      "\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dWbdlUu6E4p8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460821194,
     "user_tz": -330,
     "elapsed": 1741,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_rnn_classifier import TorchRNNClassifier\n",
    "from torch_tree_nn import TorchTreeNN\n",
    "import sst\n",
    "import utils"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cwn2ygw8E4p9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460821194,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "SST_HOME = os.path.join('data', 'sentiment')"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcnS2g5GE4p-"
   },
   "source": [
    "## Train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0shdkxn_E4p-"
   },
   "source": [
    "Our primary train set is the SST-3 train set:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kFG0_SnEE4p-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460822056,
     "user_tz": -330,
     "elapsed": 864,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "sst_train = sst.train_reader(SST_HOME)"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kooo6r6XE4p_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460822057,
     "user_tz": -330,
     "elapsed": 6,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "7f454de3-e774-4e51-e811-7ea71f6babfb"
   },
   "source": [
    "sst_train.shape[0]"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8544"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXGiUhxnE4qB"
   },
   "source": [
    "## Dev sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uS_E137E4qB"
   },
   "source": [
    "We have two development set. SST3-dev consists of sentences from movie reviews, just like SST-3 train:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jeaAnqwIE4qB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460822057,
     "user_tz": -330,
     "elapsed": 5,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "sst_dev = sst.dev_reader(SST_HOME)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The bakeoff dev set consists of sentences from restaurant reviews:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WBj6n6YQE4qB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460822058,
     "user_tz": -330,
     "elapsed": 6,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "bakeoff_dev = sst.bakeoff_dev_reader(SST_HOME)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7x1JPyNLE4qC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460822058,
     "user_tz": -330,
     "elapsed": 5,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "e2744543-2eb3-4502-b2a9-84b4a0676780"
   },
   "source": [
    "bakeoff_dev.sample(3, random_state=1).to_dict(orient='records')"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'example_id': 57,\n",
       "  'is_subtree': 0,\n",
       "  'label': 'neutral',\n",
       "  'sentence': 'I would recommend that you make reservations in advance.'},\n",
       " {'example_id': 590,\n",
       "  'is_subtree': 0,\n",
       "  'label': 'positive',\n",
       "  'sentence': 'We were welcomed warmly.'},\n",
       " {'example_id': 1968,\n",
       "  'is_subtree': 0,\n",
       "  'label': 'neutral',\n",
       "  'sentence': 'We have been to Oceanaire twice in the last 6 weeks.'}]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHqPk9MgE4qC"
   },
   "source": [
    "Here is the label distribution:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmylZTi-E4qC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460822058,
     "user_tz": -330,
     "elapsed": 5,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "b6ac1176-12f7-4b4e-cbcb-08f5b1505974"
   },
   "source": [
    "bakeoff_dev.label.value_counts()"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "neutral     1019\n",
       "positive     777\n",
       "negative     565\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtsw5Kh2E4qC"
   },
   "source": [
    "The label distribution for the corresponding test set is similar to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41k3pje5E4qD"
   },
   "source": [
    "## A softmax baseline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mh5b0WNME4qD"
   },
   "source": [
    "def unigrams_phi(text):\n",
    "    return Counter(text.split())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJT3aiJTE4qD"
   },
   "source": [
    "Thin wrapper around `LogisticRegression` for the sake of `sst.experiment`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KL6j1QRuE4qD"
   },
   "source": [
    "def fit_softmax_classifier(X, y):\n",
    "    mod = LogisticRegression(\n",
    "        fit_intercept=True,\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr')\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mzQkYO9E4qD"
   },
   "source": [
    "The experimental run with some notes:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1ZH2NLPE4qE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631380718586,
     "user_tz": -330,
     "elapsed": 2729,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "906cf4a9-c061-44e6-9764-39b0bd333707"
   },
   "source": [
    "softmax_experiment = sst.experiment(\n",
    "    sst.train_reader(SST_HOME),\n",
    "    unigrams_phi,\n",
    "    fit_softmax_classifier,\n",
    "    assess_dataframes=[sst_dev, bakeoff_dev])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.628     0.689     0.657       428\n",
      "     neutral      0.343     0.153     0.211       229\n",
      "    positive      0.629     0.750     0.684       444\n",
      "\n",
      "    accuracy                          0.602      1101\n",
      "   macro avg      0.533     0.531     0.518      1101\n",
      "weighted avg      0.569     0.602     0.575      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.272     0.690     0.390       565\n",
      "     neutral      0.429     0.113     0.179      1019\n",
      "    positive      0.409     0.346     0.375       777\n",
      "\n",
      "    accuracy                          0.328      2361\n",
      "   macro avg      0.370     0.383     0.315      2361\n",
      "weighted avg      0.385     0.328     0.294      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.416\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W46vEUopcrjX"
   },
   "source": [
    "**_SST dev score: 0.518_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0gli5RcE4qE"
   },
   "source": [
    "## RNNClassifier wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R-Ueld2E4qE"
   },
   "source": [
    "To featurize examples for an RNN, we can just get the words in order, letting the model take care of mapping them into an embedding space."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Hdmu7GOE4qE"
   },
   "source": [
    "def rnn_phi(text):\n",
    "    return text.split()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7uhiXm4vE4qF"
   },
   "source": [
    "def fit_rnn_classifier(X, y):\n",
    "    sst_glove_vocab = utils.get_vocab(X, mincount=2)\n",
    "    mod = TorchRNNClassifier(\n",
    "        sst_glove_vocab,\n",
    "        early_stopping=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZXdYTrzE4qF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631380737141,
     "user_tz": -330,
     "elapsed": 18557,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "76ab5679-6275-45e4-92c0-ac63ffd96ded"
   },
   "source": [
    "rnn_experiment = sst.experiment(\n",
    "    sst.train_reader(SST_HOME),\n",
    "    rnn_phi,\n",
    "    fit_rnn_classifier,\n",
    "    vectorize=False,  # For deep learning, use `vectorize=False`.\n",
    "    assess_dataframes=[sst_dev, bakeoff_dev])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 82. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.07533295871689916"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.621     0.577     0.598       428\n",
      "     neutral      0.266     0.336     0.297       229\n",
      "    positive      0.617     0.574     0.595       444\n",
      "\n",
      "    accuracy                          0.526      1101\n",
      "   macro avg      0.501     0.496     0.497      1101\n",
      "weighted avg      0.545     0.526     0.534      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.279     0.361     0.315       565\n",
      "     neutral      0.476     0.342     0.398      1019\n",
      "    positive      0.410     0.475     0.440       777\n",
      "\n",
      "    accuracy                          0.390      2361\n",
      "   macro avg      0.389     0.392     0.384      2361\n",
      "weighted avg      0.407     0.390     0.392      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.440\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UH5DmQgrc6EN"
   },
   "source": [
    "**_SST dev score: 0.475_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d4h1Eb6E4qF"
   },
   "source": [
    "## Error analysis\n",
    "\n",
    "This section begins to build an error-analysis framework using the dicts returned by `sst.experiment`. These have the following structure:\n",
    "\n",
    "```\n",
    "'model': trained model\n",
    "'phi': the feature function used\n",
    "'train_dataset':\n",
    "   'X': feature matrix\n",
    "   'y': list of labels\n",
    "   'vectorizer': DictVectorizer,\n",
    "   'raw_examples': list of raw inputs, before featurizing   \n",
    "'assess_datasets': list of datasets, each with the same structure as the value of 'train_dataset'\n",
    "'predictions': list of lists of predictions on the assessment datasets\n",
    "'metric': `score_func.__name__`, where `score_func` is an `sst.experiment` argument\n",
    "'score': the `score_func` score on the each of the assessment dataasets\n",
    "```\n",
    "The following function just finds mistakes, and returns a `pd.DataFrame` for easy subsequent processing:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qe1k1To_E4qF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631498391185,
     "user_tz": -330,
     "elapsed": 761,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "def find_errors(experiment):\n",
    "    \"\"\"Find mistaken predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment : dict\n",
    "        As returned by `sst.experiment`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for i, dataset in enumerate(experiment['assess_datasets']):\n",
    "        df = pd.DataFrame({\n",
    "            'raw_examples': dataset['raw_examples'],\n",
    "            'predicted': experiment['predictions'][i],\n",
    "            'gold': dataset['y']})\n",
    "        df['correct'] = df['predicted'] == df['gold']\n",
    "        df['dataset'] = i\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ],
   "execution_count": 182,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jxchf08zE4qF"
   },
   "source": [
    "softmax_analysis = find_errors(softmax_experiment)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vW-b4oT7E4qG"
   },
   "source": [
    "rnn_analysis = find_errors(rnn_experiment)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWfYkEzPE4qG"
   },
   "source": [
    "Here we merge the softmax and RNN experiments into a single DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3q6tAMtBE4qG"
   },
   "source": [
    "analysis = softmax_analysis.merge(\n",
    "    rnn_analysis, left_on='raw_examples', right_on='raw_examples')\n",
    "\n",
    "analysis = analysis.drop('gold_y', axis=1).rename(columns={'gold_x': 'gold'})"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PP8XIGY9E4qG"
   },
   "source": [
    "# Examples where the softmax model is correct, the RNN is not,\n",
    "# and the gold label is 'positive'\n",
    "\n",
    "error_group = analysis[\n",
    "    (analysis['predicted_x'] == analysis['gold'])\n",
    "    &\n",
    "    (analysis['predicted_y'] != analysis['gold'])\n",
    "    &\n",
    "    (analysis['gold'] == 'positive')\n",
    "]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBVRzuHuE4qG",
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1631246288962,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     },
     "user_tz": -330
    },
    "outputId": "c7256ea9-5bf4-499c-9b99-4419e6de227e"
   },
   "source": [
    "error_group.shape[0]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPZLBHKEE4qH",
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1631246289563,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     },
     "user_tz": -330
    },
    "outputId": "b8ee191f-175b-4b5c-f6c0-e9d33914475b"
   },
   "source": [
    "for ex in error_group['raw_examples'].sample(5, random_state=1):\n",
    "    print(\"=\"*70)\n",
    "    print(ex)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "That is a compliment to Kuras and Miller .\n",
      "======================================================================\n",
      "We tried a couple of the new items on the menu and the manager even came by to ask us for feedback.\n",
      "======================================================================\n",
      "Martin and Barbara are complex characters -- sometimes tender , sometimes angry -- and the delicate performances by Sven Wollter and Viveka Seldahl make their hopes and frustrations vivid .\n",
      "======================================================================\n",
      "Ok, I love good food and good service wghich was provited at Mortons Sat.\n",
      "======================================================================\n",
      "Thanks to Scott 's charismatic Roger and Eisenberg 's sweet nephew , Roger Dodger is one of the most compelling variations on In the Company of Men .\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD12-AfbE4qI"
   },
   "source": [
    "### A more powerful vector-averaging baseline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E_SiDZ_ZE4qJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631460822744,
     "user_tz": -330,
     "elapsed": 690,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "\n",
    "def fit_shallow_neural_classifier_with_hyperparameter_search(X, y):\n",
    "    basemod = TorchShallowNeuralClassifier(\n",
    "        early_stopping=True)\n",
    "    cv = 3\n",
    "    param_grid = {\n",
    "        'hidden_dim': [50, 100, 200],\n",
    "        'hidden_activation': [nn.Tanh(), nn.ReLU()]}\n",
    "    \n",
    "    bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "        X, y, basemod, cv, param_grid)\n",
    "    \n",
    "    return bestmod\n"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOmxr7dl8QER",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631380838042,
     "user_tz": -330,
     "elapsed": 100909,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "6ef491fe-02dc-4b3d-a1b4-bc1f20aae1a9"
   },
   "source": [
    "# testing the above fit against the logistic regression performance\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    DATA_HOME = 'data'\n",
    "    GLOVE_HOME = os.path.join(DATA_HOME, 'glove.6B')\n",
    "\n",
    "    glove_lookup = utils.glove2dict(\n",
    "        os.path.join(GLOVE_HOME, 'glove.6B.300d.txt'))\n",
    "    \n",
    "    def vsm_phi(text, lookup, np_func=np.mean):\n",
    "        \"\"\"Represent `tree` as a combination of the vector of its words.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "\n",
    "        lookup : dict\n",
    "            From words to vectors.\n",
    "\n",
    "        np_func : function (default: np.sum)\n",
    "            A numpy matrix operation that can be applied columnwise,\n",
    "            like `np.mean`, `np.sum`, or `np.prod`. The requirement is that\n",
    "            the function take `axis=0` as one of its arguments (to ensure\n",
    "            columnwise combination) and that it return a vector of a\n",
    "            fixed length, no matter what the size of the tree is.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array, dimension `X.shape[1]`\n",
    "\n",
    "        \"\"\"\n",
    "        allvecs = np.array([lookup[w] for w in text.split() if w in lookup])\n",
    "        if len(allvecs) == 0:\n",
    "            dim = len(next(iter(lookup.values())))\n",
    "            feats = np.zeros(dim)\n",
    "        else:\n",
    "            feats = np_func(allvecs, axis=0)\n",
    "        return feats\n",
    "\n",
    "    def glove_phi(text, np_func=np.mean):\n",
    "        return vsm_phi(text, glove_lookup, np_func=np_func)\n",
    "\n",
    "    shallow_nn_classifier_opt_glv_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        glove_phi,\n",
    "        fit_shallow_neural_classifier_with_hyperparameter_search,\n",
    "        assess_dataframes=sst_dev,\n",
    "        vectorize=False)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 40. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 5.844003677368164"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'hidden_activation': ReLU(), 'hidden_dim': 200}\n",
      "Best score: 0.535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.614     0.736     0.670       428\n",
      "     neutral      0.510     0.114     0.186       229\n",
      "    positive      0.637     0.770     0.697       444\n",
      "\n",
      "    accuracy                          0.620      1101\n",
      "   macro avg      0.587     0.540     0.517      1101\n",
      "weighted avg      0.602     0.620     0.580      1101\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fB3u0WcZDv9H"
   },
   "source": [
    "An hyperparameter optimized shallow NN performs better than a Linear Classifier on GloVe mean-aggregated sentence represenations. **Improved from 0.48 macro-f1 score for the later to 0.534 for the former.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxiIeHlzE4qJ"
   },
   "source": [
    "### BERT encoding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z48eQVQPE4qJ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "ef4a007d34654e5ca79c41ee9b68a0e7",
      "5a2cb095058141eba555ee09cd54dc37",
      "41d8d04b55cb41ab8bdd29a66ebcfc6c",
      "7e40ae05da1240eaacc15696aee51b4b",
      "6189d115bc424bad888f484a4d202e29",
      "23a84edf2e434170a18fbb7d20b9b0d8",
      "70d076bfceb8438db5114c8f22365372",
      "4ea06e598be84919b76e093853b8d62a",
      "ce557dad1b5e4218827fefef3df55e92",
      "998792a222224ce5aab18724e34bd1a2",
      "652f2f6add42459db51ada269a8c5203",
      "ee842f353f674722abbcc59c98458b9c",
      "d9f69fdba32349b5bf093f31044ab4c4",
      "bfd5358bb23940d9bc5b6897c1c1b303",
      "376e1466d12b4541a0bb2df06741a14a",
      "9c4a0324473d4305a1f54406cbd91c8b",
      "0bde278e2a014c0dab704b8fdee6bd2a",
      "915234df03ae4c9db2b04fd5d6f75a8e",
      "4763ed0be807452f94473ddb98428a21",
      "630b7f7df2234cb98c196f4caf28f281",
      "5abe0b0d066b41d19cb20dafd3b02139",
      "48700b430ab8421aab0ce8c8a8283234",
      "0806d8df1976451ca0873742920b7576",
      "a8d91ebfeda046a6a9eaf9884139cb26",
      "6f6a325bee1646d9ad96259ab43e74d0",
      "2aa98d0fe827422a99c309a869a64757",
      "125e937fad444112a69da38c5a1d4522",
      "e74bc431adec4c41a1e70f0e1a1444d0",
      "4714d6f206ea41d5a1fe479a7ecfe992",
      "a9f88d1c46a04f8fb8fe82c27532b4e7",
      "765187d1c80641cda81378c6265c35fc",
      "65385a4d835d41e7a2b2b5cd4737bfab",
      "4d79f43a197246758b3996ab569c0066"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631461388855,
     "user_tz": -330,
     "elapsed": 12185,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "9de0b2ee-a9b2-4f0e-c6f4-60154d48fcf0"
   },
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import vsm\n",
    "\n",
    "bert_weights_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "bert_model = BertModel.from_pretrained(bert_weights_name)\n",
    "\n",
    "def hf_cls_phi(text):\n",
    "    text_bert_ids = vsm.hf_encode(text, bert_tokenizer,\n",
    "                                   add_special_tokens=True)\n",
    "\n",
    "    text_bert_reps = vsm.hf_represent(text_bert_ids, bert_model, layer=-1)\n",
    "\n",
    "    text_aggr_bert_rep = text_bert_reps[0, 0, :]\n",
    "\n",
    "    return text_aggr_bert_rep.cpu().numpy()"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4a007d34654e5ca79c41ee9b68a0e7",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee842f353f674722abbcc59c98458b9c",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0806d8df1976451ca0873742920b7576",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEpcokLaPB4I",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631381525842,
     "user_tz": -330,
     "elapsed": 678568,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "0a01122e-dc48-4351-b79f-cdd6d403dabf"
   },
   "source": [
    "# experimental test to verify if bert repr would perform better than GloVe's\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    def hf_cls_phi_tensor(text):\n",
    "        text_bert_ids = vsm.hf_encode(text, bert_tokenizer, add_special_tokens=True)\n",
    "        text_bert_reps = vsm.hf_represent(text_bert_ids, bert_model, layer=-1)\n",
    "        text_aggr_bert_rep = text_bert_reps[0, 0, :]\n",
    "        return text_aggr_bert_rep.numpy()\n",
    "\n",
    "\n",
    "    shallow_nn_classifier_opt_bert_cls_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        hf_cls_phi_tensor,\n",
    "        fit_shallow_neural_classifier_with_hyperparameter_search,\n",
    "        assess_dataframes=sst_dev,\n",
    "        vectorize=False)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 33. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 4.920585095882416"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'hidden_activation': ReLU(), 'hidden_dim': 100}\n",
      "Best score: 0.604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.729     0.752     0.740       428\n",
      "     neutral      0.371     0.170     0.234       229\n",
      "    positive      0.693     0.865     0.770       444\n",
      "\n",
      "    accuracy                          0.677      1101\n",
      "   macro avg      0.598     0.596     0.581      1101\n",
      "weighted avg      0.640     0.677     0.647      1101\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24rknzt1P9ll"
   },
   "source": [
    "The results show that the bert based feature vectors perform better than the GloVe feature vectors, when the fit model (shallow neural network) and the hyper-parameter search space is kept the same. **A gain from 0.50 to 0.609.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwVV-qj2E4qK"
   },
   "source": [
    "### The Original system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7I2fGeoNuK0"
   },
   "source": [
    "There are various ways in which we can explore this problem. Exploring all of the ideas/variations in a short span is also not feasible. Hence, we list certain subsections/ideas where we feel an **improvement** is possible. Then we will work on all/many of those depending on time constraints.\n",
    "\n",
    "1. Its almost certain that including a training data set from the restaurant/product review will contribute to the performance on dev/test sets we have. **We will try to include the dynasent dataset.**\n",
    "2. **Training on sub-sentences and their labels** is again an extremely great way to improve on sentiment analysis.\n",
    "3. Various ways in which we can **extract/construct feature vectors** from the sentences.\n",
    "4. Various ways in which we can fit these features for the corresponding sentiment response (various models + various **hyperparameters**). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPSxqJvuU7nY"
   },
   "source": [
    "#### 1. Additional Datasets (DynaSent)\n",
    "\n",
    "We try including the dynasent (yelp-based) restaurant/product review dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sY8GdCQ0Vq2s",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631461113528,
     "user_tz": -330,
     "elapsed": 290785,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "c3c3b3a6-6578-4165-8d18-e420fea0137d"
   },
   "source": [
    "# loading dynasent dataset (revision 1).\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    import json\n",
    "\n",
    "    def load_dataset(*src_filenames, labels=None):\n",
    "        data = []\n",
    "        for filename in src_filenames:\n",
    "            with open(filename) as f:\n",
    "                for line in f:\n",
    "                    d = json.loads(line)\n",
    "                    if labels is None or d['gold_label'] in labels:\n",
    "                        data.append(d)\n",
    "        return data\n",
    "    \n",
    "    r1_train_filename = os.path.join(SST_HOME, 'dynasent-v1.1', 'dynasent-v1.1-round01-yelp-train.jsonl')\n",
    "    r2_train_filename = os.path.join(SST_HOME, 'dynasent-v1.1', 'dynasent-v1.1-round02-dynabench-train.jsonl')\n",
    "    ternary_labels = ('positive', 'negative', 'neutral')\n",
    "\n",
    "    r1_train = load_dataset(r1_train_filename, labels=ternary_labels)\n",
    "    r2_train = load_dataset(r2_train_filename, labels=ternary_labels)\n",
    "    # X_train, y_train = zip(*[(d['sentence'], d['gold_label']) for d in r1_train])\n",
    "\n",
    "    dsent_train = pd.DataFrame(columns = [\"sentence\", \"label\"])\n",
    "\n",
    "    for d in r1_train:\n",
    "        if(len(d['sentence']) > 512):\n",
    "            continue\n",
    "        dsent_train = dsent_train.append({'sentence': d['sentence'], 'label': d['gold_label']}, ignore_index = True)\n",
    "        \n",
    "    for d in r2_train:\n",
    "        if(len(d['sentence']) > 512):\n",
    "            continue\n",
    "        dsent_train = dsent_train.append({'sentence': d['sentence'], 'label': d['gold_label']}, ignore_index = True)\n",
    "\n",
    "    print(dsent_train.head())"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                            sentence     label\n",
      "0  Roto-Rooter is always good when you need someo...  positive\n",
      "1  It's so worth the price of cox service over he...  positive\n",
      "2  I placed my order of \"sticky ribs\" as an appet...   neutral\n",
      "3  There is mandatory valet parking, so make sure...   neutral\n",
      "4                  My wife and I couldn't finish it.   neutral\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JP40i2Po4-V5"
   },
   "source": [
    "# running a sample experiment on it to make sure it works with our pipeline\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     softmax_classifier_unigram_phi_exp = sst.experiment(\n",
    "#         dsent_train,\n",
    "#         unigrams_phi,\n",
    "#         fit_softmax_classifier,\n",
    "#         assess_dataframes=[sst_dev, bakeoff_dev])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "As per our expectation, **_the score is good for the dataset 2, but bad on the sst dataset (dataset 1)_**, when using only the dsent_train. This will later be good for both when we train on both type of datasets. So the score can be improved simply by augmenting the dataset too. The other optimisations are a \"plus\" to this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSQNZqBT7pj8"
   },
   "source": [
    "**_A look on the dynasent dataset_**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "wgKi7S6V7q7H",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631482596727,
     "user_tz": -330,
     "elapsed": 469,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "efd1c91f-da50-49b6-8c3e-1cc74a81c625"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    _ = dsent_train.sentence.str.len().hist().set_ylabel(\"Length in characters\")"
   ],
   "execution_count": 112,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCYgDXQU8rja"
   },
   "source": [
    "**_Some samples need to be trimmed here as bert does not except sentences beyond 512 characters._**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "IyQEYRR381Uz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631482850323,
     "user_tz": -330,
     "elapsed": 428,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "dff7cde1-b007-451e-cc1a-58a2e7fc6783"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    dsent_train['word_count'] = dsent_train.sentence.str.split().apply(len)\n",
    "\n",
    "    _ = dsent_train['word_count'].hist().set_ylabel(\"Length in words\")"
   ],
   "execution_count": 113,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "nYSyw8F09QRx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631482900522,
     "user_tz": -330,
     "elapsed": 451,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "2f611d24-285f-4c95-a67d-0204bc506641"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    _ = dsent_train.boxplot(\"word_count\", by=\"label\")"
   ],
   "execution_count": 115,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qwDOm_L9ayE"
   },
   "source": [
    "**_Many outliers in this dataset_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xg_84nSA4-V5"
   },
   "source": [
    "Since we know that including subtrees from SST dataset almost anyways leads to a performance improvement, we will definitely make this optimization on the dataset. Although, we prefer to do this later, during the research for a good model. This is because any model trained on all the subtrees takes exceptional amount of training time. **_This saves the compute resources during the research_**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5TTnjiJ4-V5"
   },
   "source": [
    "#### 2.1. Tokenizer, Sentiment-based\n",
    "\n",
    "Lets use a sentiment aware tokenizer and see its gains. If possible, lets see if performance improves on negation/parts of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EJRgi4X34-V5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631507993282,
     "user_tz": -330,
     "elapsed": 362,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    from nltk.tokenize import TweetTokenizer\n",
    "    tknzr = TweetTokenizer(preserve_case=False)\n",
    "\n",
    "    def tweet_token_ctr_phi(text):\n",
    "        return Counter(tknzr.tokenize(text))\n",
    "    \n",
    "    def tweet_token_phi(text):\n",
    "        return tknzr.tokenize(text)"
   ],
   "execution_count": 202,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W94uU6Oc4-V5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631381720078,
     "user_tz": -330,
     "elapsed": 193596,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "d60334c4-7d0b-4ec3-a4fb-dd4edfe124a2"
   },
   "source": [
    "# Lets see how it performs. This might suggest complex meanings (as it is a sentiment based tokenization), \n",
    "# and hence lets try using a non-linear model's performance as a baseline for it\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    shallow_nn_classifier_opt_tweet_token_ctr_phi_experiment = sst.experiment(\n",
    "            sst_train,\n",
    "            tweet_token_ctr_phi,\n",
    "            fit_shallow_neural_classifier_with_hyperparameter_search,\n",
    "            assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "            vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 26. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.1551160365343094"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'hidden_activation': ReLU(), 'hidden_dim': 50}\n",
      "Best score: 0.530\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.633     0.654     0.644       428\n",
      "     neutral      0.252     0.140     0.180       229\n",
      "    positive      0.639     0.766     0.697       444\n",
      "\n",
      "    accuracy                          0.592      1101\n",
      "   macro avg      0.508     0.520     0.507      1101\n",
      "weighted avg      0.556     0.592     0.569      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.303     0.600     0.403       565\n",
      "     neutral      0.449     0.178     0.255      1019\n",
      "    positive      0.471     0.510     0.489       777\n",
      "\n",
      "    accuracy                          0.388      2361\n",
      "   macro avg      0.408     0.429     0.382      2361\n",
      "weighted avg      0.421     0.388     0.367      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.445\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8sq08lt4-V5"
   },
   "source": [
    "We consider a Shallow Neural Network a preliminary non-linear baseline for any peripheral optimization we do with the experiment. **_We assume that if a simple NN with some non linearity can fit a complex relationship to some extent, then complex models like RNN/LSTM would be capalble of the same, maybe even more._** **_SST dev score: 0.521_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47XJkLFv4-V5"
   },
   "source": [
    "#### 2.2. Tokenizer, Negation-based\n",
    "With the use of regex from references [from Chris Potts' work](http://sentiment.christopherpotts.net/lingstruc.html#approach), we are trying to build a negation tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HB359AyH4-V5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631381720078,
     "user_tz": -330,
     "elapsed": 9,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "53e882c9-3284-4eb8-a6d9-7f7802ff248c"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    import regex as re\n",
    "\n",
    "    # not so perfect regex, but suffices our cause\n",
    "    neg_string = r\"\"\"\n",
    "            \\b(?:never|no|nothing|nowhere|noone|none|not|\n",
    "            havent|hasnt|hadnt|cant|couldnt|shouldnt|\n",
    "            wont|wouldnt|dont|doesnt|didnt|isnt|arent|aint)|n't\n",
    "            \\b[\\w\\s]+[^\\w\\s]\"\"\"\n",
    "    \n",
    "    neg_regex = re.compile(neg_string, re.VERBOSE | re.I | re.UNICODE)\n",
    "\n",
    "    def tweet_token_neg_phi(text):\n",
    "        s = re.sub(neg_regex, \n",
    "                                 lambda match: re.sub(r'(\\s+)(\\w+)', r'\\1\\2_NEG', match.group(0)),\n",
    "                                 text)\n",
    "        return tweet_token_phi(s)\n",
    "\n",
    "    def tweet_token_neg_ctr_phi(text):\n",
    "        s = re.sub(neg_regex, \n",
    "                                 lambda match: re.sub(r'(\\s+)(\\w+)', r'\\1\\2_NEG', match.group(0)),\n",
    "                                 text)\n",
    "        return tweet_token_ctr_phi(s)\n",
    "    \n",
    "    print(tweet_token_neg_phi(\"I mightn't go to school.\"))\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['i', \"mightn't\", 'go_neg', 'to_neg', 'school_neg', '.']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0vEpWO84-V6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631381952853,
     "user_tz": -330,
     "elapsed": 232778,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "6d9b9aea-2267-4935-9e29-928f67822dd1"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    shallow_nn_classifier_opt_tweet_token_neg_ctr_phi_experiment = sst.experiment(\n",
    "            sst_train,\n",
    "            tweet_token_neg_ctr_phi,\n",
    "            fit_shallow_neural_classifier_with_hyperparameter_search,\n",
    "            assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "            vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 26. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.3303545117378235"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'hidden_activation': Tanh(), 'hidden_dim': 200}\n",
      "Best score: 0.546\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.629     0.680     0.653       428\n",
      "     neutral      0.306     0.166     0.215       229\n",
      "    positive      0.650     0.752     0.697       444\n",
      "\n",
      "    accuracy                          0.602      1101\n",
      "   macro avg      0.528     0.533     0.522      1101\n",
      "weighted avg      0.570     0.602     0.580      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.298     0.625     0.404       565\n",
      "     neutral      0.428     0.170     0.243      1019\n",
      "    positive      0.477     0.475     0.476       777\n",
      "\n",
      "    accuracy                          0.379      2361\n",
      "   macro avg      0.401     0.423     0.374      2361\n",
      "weighted avg      0.413     0.379     0.358      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.448\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGP4Ea_64-V6"
   },
   "source": [
    "**_NEG tagging + sentiment tokenizer works a tad better than simple sentiment tokenizer_**. Other recurrent/sequence models like RNN/LSTM/BERT will, through context, learn this negation concept anyways. Moreover, **_this regex does not work with multiple nested negations. it also does not work with casual words like \"dont\" instead of \"don't\"._** We might still still proceed with it, but we keep, plain sentiment-token in the pipeline too. **_SST dev score: 0.519_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxrE_LdR4-V7"
   },
   "source": [
    "#### 2.3 Tokenizer, n-gram phi?\n",
    "Lets see if there is an advantage over a unigram phi"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etcf0FUz4-V7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631380287621,
     "user_tz": -330,
     "elapsed": 381,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "fd48968c-d611-4046-e490-c607d1b5e351"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from nltk import ngrams\n",
    "    \n",
    "    def multigram_phi(text):\n",
    "        n_gram_factor = 2\n",
    "        n_grams = ngrams(text.split(), n_gram_factor)\n",
    "        \n",
    "        n_grams_list = [n_gram for n_gram in n_grams]\n",
    "        return n_grams_list\n",
    "    \n",
    "    def multigram_tweet_token_phi(text):\n",
    "        n_gram_factor = 2\n",
    "        n_grams = ngrams(tweet_token_phi(text), n_gram_factor)\n",
    "        n_grams_list = [n_gram for n_gram in n_grams]\n",
    "        return n_grams_list\n",
    "    \n",
    "    def multigram_tweet_token_ctr_phi(text):\n",
    "        return Counter(multigram_tweet_token_phi(text))\n",
    "    \n",
    "    print(multigram_tweet_token_ctr_phi(\"I want to go to school today.\"))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({('i', 'want'): 1, ('want', 'to'): 1, ('to', 'go'): 1, ('go', 'to'): 1, ('to', 'school'): 1, ('school', 'today'): 1, ('today', '.'): 1})\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2VbN4Pg14-V7"
   },
   "source": [
    "# trying to guage a bi-gram's performance (***EXTREMELY MEMORY INTENSIVE***)\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     shallow_nn_classifier_opt_multigram_tweet_token_ctr_phi_experiment = sst.experiment(\n",
    "#             sst_train,\n",
    "#             multigram_tweet_token_ctr_phi,\n",
    "#             fit_shallow_neural_classifier_with_hyperparameter_search,\n",
    "#             assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "#             vectorize=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caPzSFbwW4Te"
   },
   "source": [
    "Bi-grams and other n > 2 grams seem to be quite promising. But they have a ramped up memory requirement. For example here, for an L length sentence, there will be L-1 bi-grams and while there might be repeated unigrams in a sentence, it is **extremely rare** to find repeated 2-grams. Hence, the size of the feature matrix will almost always remain ~ O(L), which suggests that this works more like **rote-learning**. Sufficient dataset inference from this kind of model should provide **good performance**, but that would never justify the huge memory requirements it has. \n",
    "\n",
    "As a practical example, **the above cell crashes even the ColabPro runtime**. Hence, not proceeding with multi-grams in our setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlPoXVwxkOW6"
   },
   "source": [
    "#### 2.4 VSM from word_relatedness\n",
    "It looks like a good idea to use feature vectors from the VSMs created in the word_relatedness work. Since it performed well, the representations from it can be quite promising."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtRVLEAylO_c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631401172590,
     "user_tz": -330,
     "elapsed": 3495,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "135e9e0b-868e-4c0b-d9c6-1e683472b3b1"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    VSM_HOME = os.path.join('data', 'vsmdata')\n",
    "\n",
    "    def create_df_vsm():\n",
    "        full_matrix_df = pd.read_csv(os.path.join(VSM_HOME, \"best_devset_word_repr_vsm.csv.gz\"), index_col=0)\n",
    "        return full_matrix_df\n",
    "    \n",
    "    custom_vsm = create_df_vsm()\n",
    "\n",
    "    custom_vsm_lookup = {word:custom_vsm.loc[word] for word in custom_vsm.index}\n",
    "    \n",
    "    print(custom_vsm_lookup[\"water\"])\n",
    "    "
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       0.007726\n",
      "1      -0.002936\n",
      "2       0.001923\n",
      "3      -0.002022\n",
      "4       0.029006\n",
      "          ...   \n",
      "1275    0.009053\n",
      "1276   -0.020875\n",
      "1277    0.027672\n",
      "1278    0.033489\n",
      "1279    0.011569\n",
      "Name: water, Length: 1280, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dN9LUhmoUlf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631344742578,
     "user_tz": -330,
     "elapsed": 393,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "3d0d134a-f7d0-4804-92ed-62bdffe5f29b"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    def custom_vsm_phi(text):\n",
    "        text_list = text.split()\n",
    "        text_repr = []\n",
    "        repr_dim = len(custom_vsm.columns)\n",
    "        \n",
    "        text_repr = [list(custom_vsm.loc[word])  \n",
    "                      for word in text_list if word in custom_vsm.index]\n",
    "        \n",
    "        if len(text_repr) == 0:\n",
    "            text_repr = np.zeros(repr_dim)\n",
    "            return text_repr\n",
    "        \n",
    "        return np.mean(text_repr, axis=0)\n",
    "    \n",
    "    print(custom_vsm_phi(\"water is the new game\"))\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.00461155 -0.00676014  0.00023683 ...  0.00576954  0.01061944\n",
      "  0.00043484]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7DmrEM7q0Jo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631345082913,
     "user_tz": -330,
     "elapsed": 134130,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "e069803e-b953-49af-a208-962cc1863684"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    shallow_nn_classifier_opt_custom_vsm_phi_experiment = sst.experiment(\n",
    "            sst_train,\n",
    "            custom_vsm_phi,\n",
    "            fit_shallow_neural_classifier_with_hyperparameter_search,\n",
    "            assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "            vectorize=False)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 61. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.368035912513733"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'hidden_activation': ReLU(), 'hidden_dim': 200}\n",
      "Best score: 0.469\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.625     0.696     0.659       428\n",
      "     neutral      0.304     0.031     0.056       229\n",
      "    positive      0.592     0.802     0.681       444\n",
      "\n",
      "    accuracy                          0.600      1101\n",
      "   macro avg      0.507     0.510     0.465      1101\n",
      "weighted avg      0.545     0.600     0.542      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.296     0.761     0.426       565\n",
      "     neutral      0.456     0.091     0.152      1019\n",
      "    positive      0.457     0.414     0.435       777\n",
      "\n",
      "    accuracy                          0.358      2361\n",
      "   macro avg      0.403     0.422     0.338      2361\n",
      "weighted avg      0.418     0.358     0.311      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.401\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLagkd2Rvsui"
   },
   "source": [
    "The scores from the *limited vocabulary VSM* we created then, could not very well encode the sentences. This might majorly be because of a lack of vast vocabulary in it. Not proceeding with this in the pipeline further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLeM4zw8ccrn"
   },
   "source": [
    "#### **2.5 Pipeline till now**:\n",
    "1. Use **_dsent_train + sst_train (issubtree=True)_**\n",
    "2. Feature vectorization using: **_tweet_token_phi_**, glove_phi, tweet_token_neg_phi, **_bert pretrained embeddings_**, randomly inited embeddings\n",
    "3. Now let us explore various fit models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ws10NixVe0lg"
   },
   "source": [
    "#### 3. Various models (with hyper-param optimizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fvF8_t_6HKy"
   },
   "source": [
    "##### 3.1 SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4BWjX_YEiNmh"
   },
   "source": [
    "# sklearn's SGD Classifier\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "    def fit_sgdclassifier_with_hyperparameter_search(X, y):\n",
    "        basemod = SGDClassifier(tol=1e-4, n_jobs=-1, \n",
    "            early_stopping=True)\n",
    "        cv = 5\n",
    "        param_grid = {\n",
    "            'loss': ['hinge', 'log', 'modified_huber'],\n",
    "            'penalty': ['l1', 'l2']}\n",
    "        \n",
    "        bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "            X, y, basemod, cv, param_grid)\n",
    "        \n",
    "        return bestmod\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TiuqXx1bzzbH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631357016957,
     "user_tz": -330,
     "elapsed": 230331,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "0d958643-fd9b-465c-a38f-4d60a4271610"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    sgdclassifier_opt_tweet_token_ctr_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_ctr_phi,\n",
    "        fit_sgdclassifier_with_hyperparameter_search,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'loss': 'log', 'penalty': 'l1'}\n",
      "Best score: 0.517\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.605     0.540     0.570       428\n",
      "     neutral      0.264     0.262     0.263       229\n",
      "    positive      0.604     0.669     0.635       444\n",
      "\n",
      "    accuracy                          0.534      1101\n",
      "   macro avg      0.491     0.490     0.489      1101\n",
      "weighted avg      0.533     0.534     0.532      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.322     0.473     0.383       565\n",
      "     neutral      0.470     0.344     0.398      1019\n",
      "    positive      0.457     0.462     0.460       777\n",
      "\n",
      "    accuracy                          0.414      2361\n",
      "   macro avg      0.416     0.426     0.413      2361\n",
      "weighted avg      0.430     0.414     0.415      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.451\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ7zs5E2eg4X"
   },
   "source": [
    "**_SST dev score: 0.489_**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VA3FtjWq3Hl7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631357265789,
     "user_tz": -330,
     "elapsed": 248840,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "945c5acb-6e29-4ad0-daea-df5204a7fbf3"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    sgdclassifier_opt_tweet_token_neg_ctr_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_neg_ctr_phi,\n",
    "        fit_sgdclassifier_with_hyperparameter_search,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "Best score: 0.519\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.639     0.579     0.608       428\n",
      "     neutral      0.289     0.245     0.265       229\n",
      "    positive      0.601     0.703     0.648       444\n",
      "\n",
      "    accuracy                          0.559      1101\n",
      "   macro avg      0.510     0.509     0.507      1101\n",
      "weighted avg      0.551     0.559     0.553      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.318     0.467     0.378       565\n",
      "     neutral      0.466     0.309     0.372      1019\n",
      "    positive      0.448     0.493     0.470       777\n",
      "\n",
      "    accuracy                          0.407      2361\n",
      "   macro avg      0.411     0.423     0.407      2361\n",
      "weighted avg      0.425     0.407     0.405      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.457\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-BUkJGIf8HW"
   },
   "source": [
    "**_SST dev score: 0.507_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAh_fA-c5d42"
   },
   "source": [
    "The linear classifiers dont perform extremely well, but **_after some optimization they reach a value around 0.51_**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX4-wPZ36CQ9"
   },
   "source": [
    "##### 3.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QPeSHzfj68kE"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    def fit_logistic_with_hyperparameter_search(X, y):\n",
    "        basemod = LogisticRegression(tol=1e-4)\n",
    "        cv = 5\n",
    "        param_grid = {\n",
    "            # newton-cg, saga are quite slow and should not contribute \n",
    "            # much to the score anyways\n",
    "            'solver': ['liblinear'],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.5, 1, 2]}\n",
    "        \n",
    "        bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "            X, y, basemod, cv, param_grid)\n",
    "        \n",
    "        return bestmod\n",
    "\n",
    "    def fit_logistic_with_hyperparameter_search_2(X, y):\n",
    "        basemod = LogisticRegression(tol=1e-4, max_iter=1000)\n",
    "        cv = 5\n",
    "        param_grid = {\n",
    "            'solver': ['lbfgs'],\n",
    "            'penalty': ['l2'],\n",
    "            'C': [0.5, 1, 2]}\n",
    "        \n",
    "        bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "            X, y, basemod, cv, param_grid)\n",
    "        \n",
    "        return bestmod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EIJKYRq86fr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631381987327,
     "user_tz": -330,
     "elapsed": 34476,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "b81d7051-5698-47c1-c4b9-609474ce9820"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    logistic_opt_tweet_token_ctr_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_ctr_phi,\n",
    "        fit_logistic_with_hyperparameter_search,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'C': 2, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.526\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.620     0.666     0.642       428\n",
      "     neutral      0.304     0.153     0.203       229\n",
      "    positive      0.631     0.748     0.685       444\n",
      "\n",
      "    accuracy                          0.592      1101\n",
      "   macro avg      0.518     0.522     0.510      1101\n",
      "weighted avg      0.559     0.592     0.568      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.287     0.611     0.390       565\n",
      "     neutral      0.426     0.146     0.218      1019\n",
      "    positive      0.465     0.484     0.474       777\n",
      "\n",
      "    accuracy                          0.368      2361\n",
      "   macro avg      0.393     0.414     0.361      2361\n",
      "weighted avg      0.405     0.368     0.343      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.435\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3GN22yNj_pf"
   },
   "source": [
    "**_SST dev score: 0.510_**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cliGH21mjPoH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631383133983,
     "user_tz": -330,
     "elapsed": 1146664,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "01cbb6f0-36e9-4a93-a47e-29e21590bfab"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    logistic_opt_tweet_token_ctr_phi_experiment_2 = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_ctr_phi,\n",
    "        fit_logistic_with_hyperparameter_search_2,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score: 0.530\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.620     0.666     0.642       428\n",
      "     neutral      0.289     0.153     0.200       229\n",
      "    positive      0.631     0.739     0.680       444\n",
      "\n",
      "    accuracy                          0.589      1101\n",
      "   macro avg      0.513     0.519     0.507      1101\n",
      "weighted avg      0.555     0.589     0.566      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.293     0.627     0.399       565\n",
      "     neutral      0.410     0.145     0.214      1019\n",
      "    positive      0.468     0.476     0.472       777\n",
      "\n",
      "    accuracy                          0.369      2361\n",
      "   macro avg      0.390     0.416     0.362      2361\n",
      "weighted avg      0.401     0.369     0.343      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.435\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rDGXi5qgINx"
   },
   "source": [
    "SST dev score: 0.507 , **_not much gains with the second-derivate estimates_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irwlEMoimmzq"
   },
   "source": [
    "##### 3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ws2P6YD_mzNj"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    def fit_svm_with_hyperparameter_search(X, y):\n",
    "        basemod = SVC(tol=1e-4, class_weight='balanced', C=1, kernel='rbf',\n",
    "                      probability=False)\n",
    "        basemod.fit(X, y)\n",
    "        return basemod\n",
    "        # cv = 5\n",
    "        # param_grid = {\n",
    "        #     'C': [0.5, 1, 2],\n",
    "        #     'kernel': ['poly', 'rbf'],\n",
    "        #     'probability': [False]}\n",
    "        \n",
    "        # bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "        #     X, y, basemod, cv, param_grid)\n",
    "        \n",
    "        # return bestmod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OijoeiF4qhdJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631379282942,
     "user_tz": -330,
     "elapsed": 2742467,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "75ee2eac-ba75-43d6-8829-5d3565abe607"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    svm_opt_tweet_token_ctr_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_ctr_phi,\n",
    "        fit_svm_with_hyperparameter_search,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.633     0.610     0.621       428\n",
      "     neutral      0.296     0.288     0.292       229\n",
      "    positive      0.650     0.682     0.666       444\n",
      "\n",
      "    accuracy                          0.572      1101\n",
      "   macro avg      0.527     0.527     0.526      1101\n",
      "weighted avg      0.570     0.572     0.571      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.291     0.414     0.342       565\n",
      "     neutral      0.434     0.472     0.452      1019\n",
      "    positive      0.487     0.281     0.356       777\n",
      "\n",
      "    accuracy                          0.395      2361\n",
      "   macro avg      0.404     0.389     0.383      2361\n",
      "weighted avg      0.417     0.395     0.394      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.455\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnIXrdtZyix5"
   },
   "source": [
    "This is an extremely costly step. **_It took 45 min just to train 1 variant!!! This must be because of the O(n^2) approach on the data points it takes. Anyways, because the model as some of the top scores, it can be included for further investigation._** But its not possible to optimiza on its hyperparameters for now. **_Since it cannot be trained on a large dataset (SST+dynasent) without incurring a lot of CPU-only compute time, we still need to see if we want to include this model for the final evaluation._**\n",
    "\n",
    "**_SST dev score: 0.526_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck4WfpyQrUgs"
   },
   "source": [
    "##### 3.4 Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iuRdrVmZrc-t"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "    # the few hyper-parameters it has are okay in their defaults\n",
    "    def fit_nb(X, y):\n",
    "        mod = MultinomialNB()\n",
    "        mod.fit(X, y)\n",
    "        return mod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8WGMu86sSxp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631379859091,
     "user_tz": -330,
     "elapsed": 2038,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "514cb80b-c786-437a-e6af-04a66ef12d89"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    nb_tweet_token_ctr_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_ctr_phi,\n",
    "        fit_nb,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.632     0.757     0.689       428\n",
      "     neutral      0.357     0.044     0.078       229\n",
      "    positive      0.645     0.813     0.719       444\n",
      "\n",
      "    accuracy                          0.631      1101\n",
      "   macro avg      0.544     0.538     0.495      1101\n",
      "weighted avg      0.580     0.631     0.574      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.302     0.768     0.433       565\n",
      "     neutral      0.488     0.039     0.073      1019\n",
      "    positive      0.505     0.547     0.525       777\n",
      "\n",
      "    accuracy                          0.381      2361\n",
      "   macro avg      0.432     0.451     0.344      2361\n",
      "weighted avg      0.449     0.381     0.308      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.419\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaDaZ9u90VjB"
   },
   "source": [
    "Decent score in almost an instant execution!! This is because of the fixed steps it has to follow to calculate the priors and multiply them accordingly. **_Lets try a new variant on it using the bi-gram phi_**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WQOBwJwV034Z"
   },
   "source": [
    "# Huge memory costs even for basic aggregate operations with the Bi-grams in NB\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     nb_multigram_tweet_token_ctr_phi_experiment = sst.experiment(\n",
    "#         sst_train,\n",
    "#         multigram_tweet_token_ctr_phi,\n",
    "#         fit_nb,\n",
    "#         assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "#         vectorize=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vygXIBaO2zmU"
   },
   "source": [
    "Looks like using bi-grams simply entails huge memory costs even for simple models. So the best that can be extracted from sane resources now is the performance of a unigram tweet token.\n",
    "\n",
    "**_SST dev score: 0.495_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMUUEslQ-ymc"
   },
   "source": [
    "##### 3.5 A thin NN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ISsAfwLz-6Lt"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    class TorchCustomSoftmaxClassifier(TorchShallowNeuralClassifier):\n",
    "        def build_graph(self):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.input_dim, self.hidden_dim),\n",
    "                self.hidden_activation,\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.Linear(self.hidden_dim, self.n_classes_),\n",
    "                nn.Softmax())\n",
    "\n",
    "    def fit_torch_custom_nn(X, y):\n",
    "        basemod = TorchCustomSoftmaxClassifier(early_stopping=True, \n",
    "                                               validation_fraction=0.1,\n",
    "                                               tol=1e-5, n_iter_no_change=10,\n",
    "                                               hidden_activation=nn.ReLU())\n",
    "        cv = 3\n",
    "        param_grid = {\n",
    "            'hidden_dim': [512, 1024]}\n",
    "        \n",
    "        bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "            X, y, basemod, cv, param_grid)\n",
    "        \n",
    "        return bestmod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02xBpiW8TfH3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631387936689,
     "user_tz": -330,
     "elapsed": 68697,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "6346827f-b9c9-4ec3-f32a-8341b9d58396"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    custom_nn_opt_tweet_token_ctr_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_ctr_phi,\n",
    "        fit_torch_custom_nn,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "Stopping after epoch 25. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 4.526520609855652"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'hidden_dim': 1024}\n",
      "Best score: 0.537\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.654     0.668     0.661       428\n",
      "     neutral      0.316     0.218     0.258       229\n",
      "    positive      0.650     0.741     0.693       444\n",
      "\n",
      "    accuracy                          0.604      1101\n",
      "   macro avg      0.540     0.543     0.537      1101\n",
      "weighted avg      0.582     0.604     0.590      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.305     0.607     0.406       565\n",
      "     neutral      0.453     0.201     0.279      1019\n",
      "    positive      0.478     0.481     0.480       777\n",
      "\n",
      "    accuracy                          0.391      2361\n",
      "   macro avg      0.412     0.430     0.388      2361\n",
      "weighted avg      0.426     0.391     0.375      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.463\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJ6fCQ8CLI7v"
   },
   "source": [
    "This is a better score for us. **_With just an improvement in the simple NN model, we have improved on the baseline._**\n",
    "\n",
    "**_SST dev score: 0.542_** (Relu + hidden dim: 1024) (searched in space (ReLU, tanh, sigmoid) X (128, 256, 512, 1024, 1200, 1500, 2048 hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xriTTLZWPTBv"
   },
   "source": [
    "Now lets check this setup with glove embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMeTLV7APfO7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631387170156,
     "user_tz": -330,
     "elapsed": 34888,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "23a43c84-992b-4cf8-9866-1f612efef521"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    custom_nn_opt_glove_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        glove_phi,\n",
    "        fit_torch_custom_nn,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=False)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "Stopping after epoch 79. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.793539583683014"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'hidden_dim': 512}\n",
      "Best score: 0.485\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.609     0.743     0.669       428\n",
      "     neutral      0.476     0.044     0.080       229\n",
      "    positive      0.625     0.786     0.697       444\n",
      "\n",
      "    accuracy                          0.615      1101\n",
      "   macro avg      0.570     0.524     0.482      1101\n",
      "weighted avg      0.588     0.615     0.558      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.291     0.821     0.430       565\n",
      "     neutral      0.727     0.016     0.031      1019\n",
      "    positive      0.466     0.447     0.456       777\n",
      "\n",
      "    accuracy                          0.350      2361\n",
      "   macro avg      0.495     0.428     0.306      2361\n",
      "weighted avg      0.537     0.350     0.266      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.394\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NaBa9ITRVfW"
   },
   "source": [
    "Not that great results when we optimize Simple NN with GloVe embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DehwZWKrTaWf"
   },
   "source": [
    "##### 3.6 Avg'd Internal Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "71NzQ5wMTgj6"
   },
   "source": [
    "# Using the RNN module, we try combining the input embeddings in the model itself\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    class TorchVecAvgCustomModel(nn.Module):\n",
    "        def __init__(self, vocab_size, output_dim, device, embed_dim, hidden_dim,\n",
    "                    activation):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.embed_dim = embed_dim\n",
    "            self.output_dim = output_dim\n",
    "            self.hidden_dim = hidden_dim\n",
    "\n",
    "            self.device = device\n",
    "\n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.embed_dim)\n",
    "            self.linear1 = nn.Linear(self.embed_dim, self.hidden_dim)\n",
    "            self.activation = activation\n",
    "            self.dropout = nn.Dropout(p=0.5)\n",
    "            self.classifier_layer = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "            self.softmax = nn.Softmax()\n",
    "\n",
    "        def forward(self, X, seq_lengths):\n",
    "            embs = self.embedding(X)\n",
    "            # Mask based on the **true** lengths:\n",
    "            mask = [torch.ones(l, self.embed_dim) for l in seq_lengths]\n",
    "            mask = torch.nn.utils.rnn.pad_sequence(mask, batch_first=True)\n",
    "            mask = mask.to(self.device)\n",
    "\n",
    "            # True average:\n",
    "            mu = (embs * mask).sum(axis=1) / seq_lengths.unsqueeze(1)\n",
    "\n",
    "            mu = self.linear1(mu)\n",
    "            mu = self.activation(mu)\n",
    "            mu = self.dropout(mu)\n",
    "            mu = self.classifier_layer(mu)\n",
    "            mu = self.softmax(mu)\n",
    "\n",
    "            return mu\n",
    "\n",
    "    class TorchVecAvgCustomClassifier(TorchRNNClassifier):\n",
    "        def build_graph(self):\n",
    "            return TorchVecAvgCustomModel(\n",
    "                vocab_size=len(self.vocab),\n",
    "                output_dim=self.n_classes_,\n",
    "                device=self.device,\n",
    "                embed_dim=self.embed_dim,\n",
    "                hidden_dim=self.hidden_dim,\n",
    "                activation=self.classifier_activation)\n",
    "            \n",
    "    def fit_vecavg_custom_with_hyperparameter_search(X, y):\n",
    "        sst_train_vocab = utils.get_vocab(X, mincount=2)\n",
    "\n",
    "        basemod = TorchVecAvgCustomClassifier(\n",
    "            sst_train_vocab,\n",
    "            early_stopping=True)\n",
    "\n",
    "        param_grid = {\n",
    "            'hidden_dim': [50],\n",
    "            'embed_dim': [256],\n",
    "            'eta': [0.01]}\n",
    "\n",
    "        bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "            X, y, basemod, cv=3, param_grid=param_grid)\n",
    "\n",
    "        return bestmod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzNWi1gdiSgo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631396926096,
     "user_tz": -330,
     "elapsed": 60053,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "4ec9dd0c-55e7-45e8-fd77-7a242409106a"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    %%time\n",
    "    vecavg_custom_opt_tweet_token_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_phi,\n",
    "        fit_vecavg_custom_with_hyperparameter_search,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "        vectorize=False)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Stopping after epoch 23. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 4.9570775628089905"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'embed_dim': 256, 'eta': 0.01, 'hidden_dim': 50}\n",
      "Best score: 0.520\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.660     0.675     0.667       428\n",
      "     neutral      0.250     0.236     0.243       229\n",
      "    positive      0.669     0.673     0.671       444\n",
      "\n",
      "    accuracy                          0.583      1101\n",
      "   macro avg      0.526     0.528     0.527      1101\n",
      "weighted avg      0.578     0.583     0.581      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.310     0.644     0.418       565\n",
      "     neutral      0.458     0.285     0.351      1019\n",
      "    positive      0.471     0.335     0.391       777\n",
      "\n",
      "    accuracy                          0.387      2361\n",
      "   macro avg      0.413     0.421     0.387      2361\n",
      "weighted avg      0.427     0.387     0.380      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.457\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RqOKCxulxZT"
   },
   "source": [
    "The scores are good.\n",
    "\n",
    "**_SST dev score: 0.540_** (at 0.01 eta, hidden_dim 100, embed_dim 128), 0.532 (at 0.01 eta, hidden_dim 50, embed_dim 256). Both are really close. Checked this across (0.001, 0.01, 0.05 eta) X (50, 100, 200 hidden_dim) X (128, 256, 512 embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSprTVYrxJUA"
   },
   "source": [
    "##### 3.7 RNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i_MZniTExW19"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    def fit_rnn_with_hyperparameter_search(X, y):\n",
    "        sst_train_vocab = utils.get_vocab(X, mincount=2)\n",
    "        glove_embedding, sst_glove_vocab = utils.create_pretrained_embedding(\n",
    "            glove_lookup, sst_train_vocab)\n",
    "    \n",
    "        basemod = TorchRNNClassifier(\n",
    "            sst_train_vocab,\n",
    "            embedding=glove_embedding,\n",
    "            batch_size=25,  # Inspired by comments in the paper.\n",
    "            bidirectional=True,\n",
    "            early_stopping=True)\n",
    "\n",
    "        param_grid = {\n",
    "            'embed_dim': [50, 75, 100],\n",
    "            'hidden_dim': [50, 75, 100],\n",
    "            'eta': [0.001, 0.01]}\n",
    "\n",
    "        bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "            X, y, basemod, cv=3, param_grid=param_grid)\n",
    "\n",
    "        return bestmod\n",
    "\n",
    "    def fit_rnn_with_hyperparameter_search_2(X, y):\n",
    "        sst_train_vocab = utils.get_vocab(X, mincount=2)\n",
    "        custom_vsm_embedding, sst_custom_vsm_vocab = utils.create_pretrained_embedding(\n",
    "            custom_vsm_lookup, sst_train_vocab)\n",
    "    \n",
    "        basemod = TorchRNNClassifier(\n",
    "            sst_train_vocab,\n",
    "            embedding=custom_vsm_embedding,\n",
    "            batch_size=25,  # Inspired by comments in the paper.\n",
    "            bidirectional=True,\n",
    "            early_stopping=True)\n",
    "\n",
    "        param_grid = {\n",
    "            'embed_dim': [50, 75, 100],\n",
    "            'hidden_dim': [50, 75, 100],\n",
    "            'eta': [0.001, 0.01]}\n",
    "\n",
    "        bestmod = utils.fit_classifier_with_hyperparameter_search(\n",
    "            X, y, basemod, cv=3, param_grid=param_grid)\n",
    "\n",
    "        return bestmod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEv3yklA19Tw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631399048398,
     "user_tz": -330,
     "elapsed": 1623966,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "5d04991e-4fcd-4c4c-be52-36240b844db1"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    %%time\n",
    "    rnn_opt_glv_tweet_token_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_phi,\n",
    "        fit_rnn_with_hyperparameter_search,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "        vectorize=False)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 21. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.7301383992622732"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'embed_dim': 100, 'eta': 0.001, 'hidden_dim': 100}\n",
      "Best score: 0.557\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.694     0.640     0.666       428\n",
      "     neutral      0.333     0.314     0.324       229\n",
      "    positive      0.665     0.734     0.698       444\n",
      "\n",
      "    accuracy                          0.610      1101\n",
      "   macro avg      0.564     0.563     0.563      1101\n",
      "weighted avg      0.607     0.610     0.608      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.326     0.639     0.431       565\n",
      "     neutral      0.486     0.324     0.389      1019\n",
      "    positive      0.539     0.398     0.458       777\n",
      "\n",
      "    accuracy                          0.424      2361\n",
      "   macro avg      0.450     0.453     0.426      2361\n",
      "weighted avg      0.465     0.424     0.422      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.494\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzroipG3DRls"
   },
   "source": [
    "Good improvement. \n",
    "**_SST dev score: 0.563_** (embed_dim 100, eta 0.001, hidden_dim: 100)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sjbtUaeC4Y3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631403983958,
     "user_tz": -330,
     "elapsed": 2799737,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "18f27f67-c852-4e79-9902-f9e391243d58"
   },
   "source": [
    "# trying a lookup with by word relatedness submission\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    %%time\n",
    "    rnn_opt_custom_vsm_tweet_token_phi_experiment = sst.experiment(\n",
    "        sst_train,\n",
    "        tweet_token_phi,\n",
    "        fit_rnn_with_hyperparameter_search_2,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "        vectorize=False)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 32. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.2574434790246869"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params: {'embed_dim': 50, 'eta': 0.001, 'hidden_dim': 50}\n",
      "Best score: 0.524\n",
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.629     0.645     0.637       428\n",
      "     neutral      0.240     0.231     0.236       229\n",
      "    positive      0.673     0.669     0.671       444\n",
      "\n",
      "    accuracy                          0.569      1101\n",
      "   macro avg      0.514     0.515     0.514      1101\n",
      "weighted avg      0.566     0.569     0.567      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.304     0.584     0.400       565\n",
      "     neutral      0.457     0.311     0.370      1019\n",
      "    positive      0.503     0.376     0.430       777\n",
      "\n",
      "    accuracy                          0.398      2361\n",
      "   macro avg      0.421     0.424     0.400      2361\n",
      "weighted avg      0.435     0.398     0.397      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.457\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vol_91F91l9"
   },
   "source": [
    "Great, **_but not as great as the glove embeddings_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oALx51xjFrYm"
   },
   "source": [
    "#### 4. Building and combining the best models so far\n",
    "\n",
    "**_Since BERT is already very promising and costly to operate on, we will work on its representations and full datasets right from the start with an aim to achieve the best model so far._** In this process we will try to produce reusable objects for other top-performing models above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W575sEC0WhT"
   },
   "source": [
    "##### 4.1 Dumping reusable weights for faster model training/convergence\n",
    "\n",
    "In the below commented code, we try to optimize our workflow. **_We basically \n",
    "try to find the bert static representations for all the sentences in all the\n",
    "datasets, and then we dump them into a persistent disk. This way we will we able\n",
    "to reuse these embeddings without having to wait for the bert model to spit the\n",
    "same embeddings out again and again._**\n",
    "\n",
    "Only post this work we realize that we could have kept the full representation of sentences instead of just their means (for RNN models). **_If time permits (this process takes approximately 4Hs), we will also dump full sequence of representations and use them in our optimized RNN model above._**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "esLxA7woGPZ8"
   },
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     sst_full_train = sst.train_reader(SST_HOME, include_subtrees=True)\n",
    "#     # we should have already loaded the training dynasent dataset by now \n",
    "#     # (dsent_train)\n",
    "#     # Our complete text dataset is [sst_full_train, dsent_train]\n",
    "#     # It is a very big dataset, and hence every computation from now on is \n",
    "#     # costly\n",
    "\n",
    "#     from transformers import BertModel, BertTokenizer\n",
    "#     import vsm\n",
    "\n",
    "#     bert_weights_name = 'bert-base-uncased'\n",
    "#     bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "#     bert_model = BertModel.from_pretrained(bert_weights_name)\n",
    "\n",
    "#     train_text_bert_repr = {}\n",
    "#     global ctr\n",
    "#     ctr = 0\n",
    "\n",
    "#     def hf_bert_phi(text):\n",
    "#         text_bert_ids = vsm.hf_encode(text, bert_tokenizer, \n",
    "#                                     add_special_tokens=True)\n",
    "\n",
    "#         text_bert_reps = vsm.hf_represent(text_bert_ids, bert_model, layer=-1)\n",
    "\n",
    "#         # Index into `reps` to get the representation above [CLS].\n",
    "#         # The shape of `reps` should be (1, n, 768), where n is the\n",
    "#         # number of tokens. You need the 0th element of the 2nd dim:\n",
    "#         \n",
    "#         REMOVE THE BELOW LINE FOR UN-AVERAGED REPRESENTATION\n",
    "#         text_aggr_bert_rep = torch.mean(text_bert_reps[0], dim=0)\n",
    "\n",
    "#         # These conversions should ensure that you can work with the\n",
    "#         # representations flexibly. Feel free to change the variable\n",
    "#         # name:\n",
    "#         global ctr\n",
    "#         if ctr%100 == 0:\n",
    "#             print(\"Done for ctr \", ctr)\n",
    "#         ctr+=1\n",
    "#           \n",
    "#         THIS IS FULL REPRESENTATION\n",
    "#         text_bert_reps[0].cpu().numpy()\n",
    "\n",
    "#         return text_aggr_bert_rep.cpu().numpy()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DOjMdzZgo3p_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631438757287,
     "user_tz": -330,
     "elapsed": 409,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# Load all the datasets so that their representations can be found once and for all\n",
    "# NOTE: WE HAVEN'T USED TEST DATASETS ANYWHERE FOR ANY INFERENCES/TRAINING\n",
    "# The following steps just saves time during the training/predicting.\n",
    "\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     sst_full_dedup_train = sst.train_reader(SST_HOME, include_subtrees=True,\n",
    "#                                             dedup=True)\n",
    "#     sst_dev = sst.dev_reader(SST_HOME)\n",
    "#     sst_test = sst.test_reader(SST_HOME)\n",
    "#     bakeoff_dev = sst.bakeoff_dev_reader(SST_HOME)\n",
    "#     bakeoff_test = sst.bakeoff_test_reader(SST_HOME)\n",
    "#     # there is dsent_train already laoded"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sVDTZ0g2Nkj6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631447674450,
     "user_tz": -330,
     "elapsed": 414,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# Finding all the mean'd BERT representatiosn we know of for all text in any\n",
    "# dataset we use\n",
    "\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     # total_dataset = [sst_full_train, dsent_train, sst_dev, sst_test, bakeoff_dev, bakeoff_test]\n",
    "\n",
    "#     full_text_bert_repr = {}\n",
    "\n",
    "#     dsent_train_text_bert_repr = {dsent_train.loc[ind, \"sentence\"]: hf_bert_phi(dsent_train.loc[ind, \"sentence\"]) for ind in dsent_train.index}\n",
    "#     full_text_bert_repr = {**full_text_bert_repr, **dsent_train_text_bert_repr}\n",
    "\n",
    "#     sst_dev_text_bert_repr = {sst_dev.loc[ind, \"sentence\"]: hf_bert_phi(sst_dev.loc[ind, \"sentence\"]) for ind in sst_dev.index}\n",
    "#     full_text_bert_repr = {**full_text_bert_repr, **sst_dev_text_bert_repr}\n",
    "\n",
    "#     sst_test_text_bert_repr = {sst_test.loc[ind, \"sentence\"]: hf_bert_phi(sst_test.loc[ind, \"sentence\"]) for ind in sst_test.index}\n",
    "#     full_text_bert_repr = {**full_text_bert_repr, **sst_test_text_bert_repr}\n",
    "\n",
    "#     bakeoff_dev_text_bert_repr = {bakeoff_dev.loc[ind, \"sentence\"]: hf_bert_phi(bakeoff_dev.loc[ind, \"sentence\"]) for ind in bakeoff_dev.index}\n",
    "#     full_text_bert_repr = {**full_text_bert_repr, **bakeoff_dev_text_bert_repr}\n",
    "\n",
    "#     bakeoff_test_text_bert_repr = {bakeoff_test.loc[ind, \"sentence\"]: hf_bert_phi(bakeoff_test.loc[ind, \"sentence\"]) for ind in bakeoff_test.index}\n",
    "#     full_text_bert_repr = {**full_text_bert_repr, **bakeoff_test_text_bert_repr}\n",
    "\n",
    "#     full_text_bert_repr = {**full_text_bert_repr, **train_text_bert_repr}"
   ],
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XjrsXXLomRb6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631490986858,
     "user_tz": -330,
     "elapsed": 391,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    import pickle\n",
    "\n",
    "    def save_obj(obj, name):\n",
    "        with open(SST_HOME + '/' + name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load_obj(name):\n",
    "        with open(SST_HOME + '/' + name + '.pkl', 'rb') as f:\n",
    "            return pickle.load(f)"
   ],
   "execution_count": 125,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fz_iR86rng64",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631445914258,
     "user_tz": -330,
     "elapsed": 2351,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# Dumping all the mean'd BERT representatiosn we know of for all text in any\n",
    "# dataset we use\n",
    "\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     # sst_full_train bert repr is also saved in a stray cell and then deleted \n",
    "#     # This was done to check memory requirements\n",
    "#     save_obj(train_text_bert_repr, \"sst_full_train_text_bert_repr\")\n",
    "#     save_obj(dsent_train_text_bert_repr, \"dsent_train_text_bert_repr\")\n",
    "#     save_obj(sst_dev_text_bert_repr, \"sst_dev_text_bert_repr\")\n",
    "#     save_obj(sst_test_text_bert_repr, \"sst_test_text_bert_repr\")\n",
    "#     save_obj(bakeoff_dev_text_bert_repr, \"bakeoff_dev_text_bert_repr\")\n",
    "#     save_obj(bakeoff_test_text_bert_repr, \"bakeoff_test_text_bert_repr\")\n",
    "#     save_obj(full_text_bert_repr, \"full_text_bert_repr\")"
   ],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l8AQgJ2IwTVm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631447590988,
     "user_tz": -330,
     "elapsed": 4411,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     testing load functions\n",
    "#     test_bakeoff_dev_text_bert_repr = load_obj('bakeoff_dev_text_bert_repr')\n",
    "#     sst_full_train_text_bert_repr = load_obj('sst_full_train_text_bert_repr')"
   ],
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K1OGurlJ12SN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631447659274,
     "user_tz": -330,
     "elapsed": 411,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     print(len(bakeoff_dev_text_bert_repr)) \n",
    "#     print(len(test_bakeoff_dev_text_bert_repr))\n",
    "#     del test_bakeoff_dev_text_bert_repr\n",
    "#     print(sst_full_train_text_bert_repr[\"cold\"])"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzG05UJj3UtG"
   },
   "source": [
    "As we can see this method allowed us 2 things:\n",
    "1. A lot of static word representations from BERT\n",
    "2. A lot of phrase/full sentence/text mean'd representations from BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLhIahw1XhIb"
   },
   "source": [
    "**_Bert Contextual Word Representation for all the dataset (7 hours, 10 GBs generated)_**\n",
    "\n",
    "Using the similar methods above (except averaging the representations), we encoded the entire available dataset for quick work on RNN + contextual BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef7Hmtte3upg"
   },
   "source": [
    "##### 4.2 Tweaked BERT finetuning (Chosen)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LPShFTHY9ct0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631461311109,
     "user_tz": -330,
     "elapsed": 33216,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    sst_full_dedup_train = sst.train_reader(SST_HOME, include_subtrees=True,\n",
    "                                            dedup=True)"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "juzYfvNh31Uw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631495524378,
     "user_tz": -330,
     "elapsed": 402,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    import torch\n",
    "\n",
    "    class BertCustomClassifierModel(nn.Module):\n",
    "        def __init__(self, n_classes, weights_name='bert-base-cased'):\n",
    "            super().__init__()\n",
    "            self.n_classes = n_classes\n",
    "            self.weights_name = weights_name\n",
    "            self.bert = BertModel.from_pretrained(self.weights_name)\n",
    "            self.bert.train()\n",
    "            self.hidden_dim = self.bert.embeddings.word_embeddings.embedding_dim\n",
    "\n",
    "            self.dropout = nn.Dropout(p=0.5)\n",
    "            self.classifier_layer = nn.Linear(\n",
    "                self.hidden_dim, self.n_classes)\n",
    "\n",
    "        def forward(self, indices, mask):\n",
    "            reps = self.bert(\n",
    "                indices, attention_mask=mask)\n",
    "            hidden_bert_out = reps.pooler_output\n",
    "            out = self.dropout(hidden_bert_out)\n",
    "            out = self.classifier_layer(out)\n",
    "            return out\n",
    "\n",
    "    class BertCustomClassifier(TorchShallowNeuralClassifier):\n",
    "        def __init__(self, weights_name, *args, **kwargs):\n",
    "            self.weights_name = weights_name\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(self.weights_name)\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.params += ['weights_name']\n",
    "\n",
    "        def build_graph(self):\n",
    "            return BertCustomClassifierModel(self.n_classes_, self.weights_name)\n",
    "\n",
    "        def build_dataset(self, X, y=None):\n",
    "            data = self.tokenizer.batch_encode_plus(\n",
    "                X,\n",
    "                max_length=None,\n",
    "                add_special_tokens=True,\n",
    "                padding='longest',\n",
    "                return_attention_mask=True)\n",
    "            indices = torch.tensor(data['input_ids'])\n",
    "            mask = torch.tensor(data['attention_mask'])\n",
    "            if y is None:\n",
    "                dataset = torch.utils.data.TensorDataset(indices, mask)\n",
    "            else:\n",
    "                self.classes_ = sorted(set(y))\n",
    "                self.n_classes_ = len(self.classes_)\n",
    "                class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "                y = [class2index[label] for label in y]\n",
    "                y = torch.tensor(y)\n",
    "                dataset = torch.utils.data.TensorDataset(indices, mask, y)\n",
    "            return dataset\n",
    "    \n",
    "    def bert_noop_phi(text):\n",
    "        return text\n",
    "\n",
    "    # this search takes more than 4 hrs in a GPU, will directly use a ballpark\n",
    "    # hyperparameter value\n",
    "    \n",
    "    def fit_bert_custom_classifier_with_hyperparam(X, y):\n",
    "        mod = BertCustomClassifier(\n",
    "            weights_name='bert-base-cased',\n",
    "            batch_size=32,\n",
    "            max_iter=4, # will train on 8 more if time permits\n",
    "            n_iter_no_change=5,\n",
    "            early_stopping=True, \n",
    "            gradient_accumulation_steps = 8, \n",
    "            eta = 0.0001,\n",
    "            hidden_dim = 300\n",
    "            )\n",
    "\n",
    "        mod.fit(X, y)\n",
    "        return mod"
   ],
   "execution_count": 161,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ymi7sC3u86Q6"
   },
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     # TOOK 6 hrs on a GPU\n",
    "#     bert_custom_classifier_with_hyperparam_bert_noop_phi_experiment = sst.experiment(\n",
    "#         [sst_full_dedup_train, dsent_train],\n",
    "#         bert_noop_phi,\n",
    "#         fit_bert_custom_classifier_with_hyperparam,\n",
    "#         assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "#         vectorize=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBRORm6BsOd8"
   },
   "source": [
    "```\n",
    "Finished epoch 4 of 4; error is 290.63841717178Assessment dataset 1\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative      0.815     0.792     0.803       428\n",
    "     neutral      0.468     0.384     0.422       229\n",
    "    positive      0.777     0.869     0.820       444\n",
    "\n",
    "    accuracy                          0.738      1101\n",
    "   macro avg      0.687     0.682     0.682      1101\n",
    "weighted avg      0.727     0.738     0.731      1101\n",
    "\n",
    "Assessment dataset 2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative      0.734     0.786     0.759       565\n",
    "     neutral      0.812     0.805     0.808      1019\n",
    "    positive      0.816     0.784     0.800       777\n",
    "\n",
    "    accuracy                          0.793      2361\n",
    "   macro avg      0.787     0.791     0.789      2361\n",
    "weighted avg      0.795     0.793     0.794      2361\n",
    "\n",
    "Mean of macro-F1 scores: 0.735\n",
    "```\n",
    "**_The best score in the entire investigation so far_**. The model did not converge yet. If time permits then we will train it further for 8-10 more epochs.\n",
    "\n",
    "**_Dev Score: 0.735_**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O5o2Cce4swMH"
   },
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     # saving the model at 4 epochs\n",
    "#     torch.save(bert_custom_classifier_with_hyperparam_bert_noop_phi_experiment['model'], \n",
    "#             SST_HOME + '/bert_custom_classifier_with_hyperparam_bert_noop_phi_model')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBeSF_m3s9hc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cSXfIPRns_co",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631507642362,
     "user_tz": -330,
     "elapsed": 2808,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# loading the optimal model from persistent disk\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # 4 epoch trained model\n",
    "    optim_bert_classifier = torch.load(SST_HOME + '/' + 'bert_custom_classifier_with_hyperparam_bert_noop_phi_model')\n",
    "\n",
    "    #create minimalistic experiment model as running the entire experiment takes huge time\n",
    "    optim_bert_classifier_experiment = {'model': optim_bert_classifier, 'phi': bert_noop_phi, 'train_dataset': {'vectorizer': None}}"
   ],
   "execution_count": 199,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGRmqyLtXUYN"
   },
   "source": [
    "**_We continued with the bert training for a few more epocs and found that it started overfitting on the train-data (and loosing score on dev-data). _**The findings are as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GtqpFheCX-K-"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    def fit_optimized_bert_classifier(X, y):\n",
    "        optim_bert_classifier.max_iter = 8\n",
    "        optim_bert_classifier.fit(X, y)\n",
    "        return optim_bert_classifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MR9kojxOYgMH"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    optimized_bert_classifier_bert_noop_phi_experiment = sst.experiment(\n",
    "        [sst_full_dedup_train, dsent_train],\n",
    "        bert_noop_phi,\n",
    "        fit_optimized_bert_classifier,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "        vectorize=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCvz18ZgY2rU"
   },
   "source": [
    "```\n",
    "Stopping after epoch 8. Validation score did not improve by tol=1e-05 for more than 5 epochs. Final error is 146.14909865811933Assessment dataset 1\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative      0.772     0.832     0.801       428\n",
    "     neutral      0.515     0.380     0.437       229\n",
    "    positive      0.800     0.849     0.824       444\n",
    "\n",
    "    accuracy                          0.745      1101\n",
    "   macro avg      0.696     0.687     0.687      1101\n",
    "weighted avg      0.730     0.745     0.735      1101\n",
    "\n",
    "Assessment dataset 2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative      0.751     0.749     0.750       565\n",
    "     neutral      0.798     0.784     0.791      1019\n",
    "    positive      0.772     0.792     0.781       777\n",
    "\n",
    "    accuracy                          0.778      2361\n",
    "   macro avg      0.774     0.775     0.774      2361\n",
    "weighted avg      0.778     0.778     0.778      2361\n",
    "\n",
    "Mean of macro-F1 scores: 0.731\n",
    "```\n",
    "\n",
    "Needless to say, **_we continue with the old version of 4-epoch optimized BERT Finetuned model._** That was persisted on the disk too. The entire experiment in this subsection took approx 5 Hrs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTIkXiJIElre"
   },
   "source": [
    "##### 4.3 Bert static text embeddings on an NN (Chosen)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8PqUyzWeF6rw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631507713768,
     "user_tz": -330,
     "elapsed": 11259,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    class TorchCustomBertBasedSoftmaxClassifier(TorchShallowNeuralClassifier):\n",
    "        def build_graph(self):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.input_dim, self.hidden_dim),\n",
    "                self.hidden_activation,\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.Linear(self.hidden_dim, self.n_classes_))\n",
    "\n",
    "    def fit_torch_custom_nn_bert_based(X, y):\n",
    "        mod = TorchCustomBertBasedSoftmaxClassifier(early_stopping=True, \n",
    "                                               validation_fraction=0.1,\n",
    "                                               tol=1e-5, n_iter_no_change=10,\n",
    "                                               hidden_dim=256,\n",
    "                                               hidden_activation=nn.ReLU())\n",
    "        \n",
    "        mod.fit(X, y)\n",
    "        return mod\n",
    "\n",
    "    full_text_bert_repr = load_obj('full_text_bert_repr')\n",
    "\n",
    "    def bert_repr_phi(text):\n",
    "        return full_text_bert_repr[text]\n",
    "        \n"
   ],
   "execution_count": 200,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1QIMjvlIZku",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631470034793,
     "user_tz": -330,
     "elapsed": 101062,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "a4dc2902-b2fa-4eed-9099-def25259d258"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:   \n",
    "    custom_nn_bert_based_bert_repr_phi_experiment = sst.experiment(\n",
    "        [sst_full_dedup_train, dsent_train],\n",
    "        bert_repr_phi,\n",
    "        fit_torch_custom_nn_bert_based,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=False)"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 48. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 119.4610555768013"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.755     0.713     0.733       428\n",
      "     neutral      0.412     0.319     0.360       229\n",
      "    positive      0.717     0.840     0.774       444\n",
      "\n",
      "    accuracy                          0.682      1101\n",
      "   macro avg      0.628     0.624     0.622      1101\n",
      "weighted avg      0.669     0.682     0.672      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.711     0.611     0.657       565\n",
      "     neutral      0.733     0.810     0.770      1019\n",
      "    positive      0.734     0.709     0.721       777\n",
      "\n",
      "    accuracy                          0.729      2361\n",
      "   macro avg      0.726     0.710     0.716      2361\n",
      "weighted avg      0.728     0.729     0.727      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.669\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMjHFdxXJu_0"
   },
   "source": [
    "dev scores are: (0.609, 0.724), avg: 0.667 (hidden_dim: 512)\n",
    "\n",
    "**_dev score: (0.622, 0.716), avg: 0.669 (hidden_dim: 256)_**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f5bOCZXefisJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631475328006,
     "user_tz": -330,
     "elapsed": 409,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ: \n",
    "    # saving the model at hidden_dim -256\n",
    "    torch.save(custom_nn_bert_based_bert_repr_phi_experiment['model'], \n",
    "            SST_HOME + '/custom_nn_bert_based_bert_repr_phi_model')\n",
    "    "
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a83ihENUcRXC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631507923028,
     "user_tz": -330,
     "elapsed": 655,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# loading the optimal model from persistent disk\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    custom_nn_bert_based_bert_repr_phi_model = torch.load(SST_HOME + '/' + 'custom_nn_bert_based_bert_repr_phi_model')\n",
    "\n",
    "    #create minimalistic experiment model\n",
    "    custom_nn_bert_based_bert_repr_phi_experiment = {'model': custom_nn_bert_based_bert_repr_phi_model, 'phi': bert_repr_phi, 'train_dataset': {'vectorizer': None}}"
   ],
   "execution_count": 201,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPsEjWbeJt25"
   },
   "source": [
    "##### 4.4 Static bert in Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "grePyNxsM6hi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631475756428,
     "user_tz": -330,
     "elapsed": 428,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    def fit_logistic_bert_based(X, y):\n",
    "        mod = LogisticRegression(tol=1e-5, C=2, penalty='l2',\n",
    "                                     solver='liblinear')\n",
    "\n",
    "        mod.fit(X, y)   \n",
    "        return mod\n",
    "\n",
    "    def bert_repr_phi(text):\n",
    "        return full_text_bert_repr[text]\n",
    "\n"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Uea7NT0ND00",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631476271097,
     "user_tz": -330,
     "elapsed": 513990,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "7dab6a4e-8b56-41e6-daea-80bd151db25e"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    logistic_bert_based_bert_repr_phi_experiment = sst.experiment(\n",
    "        [sst_full_dedup_train, dsent_train],\n",
    "        bert_repr_phi,\n",
    "        fit_logistic_bert_based,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev], \n",
    "        vectorize=False)"
   ],
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.704     0.706     0.705       428\n",
      "     neutral      0.397     0.262     0.316       229\n",
      "    positive      0.710     0.833     0.767       444\n",
      "\n",
      "    accuracy                          0.665      1101\n",
      "   macro avg      0.604     0.600     0.596      1101\n",
      "weighted avg      0.643     0.665     0.649      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.675     0.533     0.595       565\n",
      "     neutral      0.697     0.803     0.746      1019\n",
      "    positive      0.718     0.686     0.702       777\n",
      "\n",
      "    accuracy                          0.700      2361\n",
      "   macro avg      0.697     0.674     0.681      2361\n",
      "weighted avg      0.699     0.700     0.696      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.638\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNvIpW7MqHxy"
   },
   "source": [
    "**_dev score: (0.596, 0.681), avg: 0.638_** for C=2, penalty=l2, solver=liblinear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCD5vmp_PzMO"
   },
   "source": [
    "##### 4.5 Word vocab based bert embedding in an RNN (Chosen)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YetMeMskP79v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631473610150,
     "user_tz": -330,
     "elapsed": 579,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    def fit_rnn_bert_based(X, y):\n",
    "        train_vocab = utils.get_vocab(X, mincount=2)\n",
    "        bert_embedding, bert_vocab = utils.create_pretrained_embedding(\n",
    "            full_text_bert_repr, train_vocab)\n",
    "    \n",
    "        mod = TorchRNNClassifier(\n",
    "            train_vocab,\n",
    "            embedding=bert_embedding,\n",
    "            batch_size=25,  # Inspired by comments in the paper.\n",
    "            bidirectional=True,\n",
    "            early_stopping=True,\n",
    "            hidden_dim=256,\n",
    "            eta=0.001)\n",
    "\n",
    "        mod.fit(X, y)\n",
    "        return mod"
   ],
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJP78-ebQUpb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631474736267,
     "user_tz": -330,
     "elapsed": 1125430,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "4e54997b-5d3f-4757-c63e-17e81eb9f900"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    %%time\n",
    "    rnn_bert_based_tweet_token_phi_experiment = sst.experiment(\n",
    "        [sst_full_dedup_train, dsent_train],\n",
    "        tweet_token_phi,\n",
    "        fit_rnn_bert_based,\n",
    "        assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "        vectorize=False)"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Stopping after epoch 13. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1380.3236185881542"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Assessment dataset 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.711     0.759     0.734       428\n",
      "     neutral      0.485     0.288     0.362       229\n",
      "    positive      0.722     0.827     0.771       444\n",
      "\n",
      "    accuracy                          0.688      1101\n",
      "   macro avg      0.640     0.625     0.622      1101\n",
      "weighted avg      0.669     0.688     0.672      1101\n",
      "\n",
      "Assessment dataset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.676     0.660     0.668       565\n",
      "     neutral      0.743     0.737     0.740      1019\n",
      "    positive      0.728     0.748     0.738       777\n",
      "\n",
      "    accuracy                          0.722      2361\n",
      "   macro avg      0.716     0.715     0.715      2361\n",
      "weighted avg      0.722     0.722     0.722      2361\n",
      "\n",
      "Mean of macro-F1 scores: 0.669\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oX8rqX3p9-_8"
   },
   "source": [
    "dev score: (0.623, 0.714), avg: 0.668 (eta 0.01, hidden_dim=100, batch:25)\n",
    "\n",
    "**_dev score: (0.622, 0.715), avg: 0.669 (eta: 0.01, hidden_dim=256, batch:25)*_**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JCRO-eGm-Ji3"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # saving the model at hidden_dim 256\n",
    "    torch.save(rnn_bert_based_tweet_token_phi_experiment['model'], \n",
    "            SST_HOME + '/rnn_bert_based_tweet_token_phi_model')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AW0u47cvc25k",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631508093901,
     "user_tz": -330,
     "elapsed": 5565,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# loading the optimal model from persistent disk\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    rnn_bert_based_tweet_token_phi_model = torch.load(SST_HOME + '/' + 'rnn_bert_based_tweet_token_phi_model')\n",
    "\n",
    "    #create minimalistic experiment model\n",
    "    rnn_bert_based_tweet_token_phi_experiment = {'model': rnn_bert_based_tweet_token_phi_model, 'phi': tweet_token_phi, 'train_dataset': {'vectorizer': None}}"
   ],
   "execution_count": 203,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxzJdE6_9zk_"
   },
   "source": [
    "##### 4.6 RNN with sequence bert embeddings (Incomplete due to large mem-requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfgBSUM9k8UB"
   },
   "source": [
    "**_The following commented code is an attempt to laod a 10GB file in segments to colab, so that relevant bert contextual mappings can be loaded into a finite memory_**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bwU7zd0camHa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631491508757,
     "user_tz": -330,
     "elapsed": 430,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     # !pip3 install pickle5\n",
    "#     import pickle5 as pickle"
   ],
   "execution_count": 131,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wD_n-0RXbDhB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631493185711,
     "user_tz": -330,
     "elapsed": 390,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     del bakeoff_test_text_bert_all_repr\n",
    "#     # Overpours the RAM on Colab. LOADING IT BY USING SEGMENTED FILES\n",
    "    # with open(SST_HOME + '/bakeoff_test_text_bert_all_repr.pkl', \"rb\") as fh:\n",
    "    #     bakeoff_test_text_bert_all_repr = pickle.load(fh)"
   ],
   "execution_count": 151,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i1Yet5PMelqv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631491772038,
     "user_tz": -330,
     "elapsed": 402,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     truncated_sst_train_bert_all_repr = {text: sst_full_dedup_train_text_bert_all_repr[text] for text in sst_train[\"sentence\"].values}\n",
    "#     truncated_dsent_train = dsent_train[:8544]\n",
    "#     truncated_dsent_train_bert_all_repr = {text: dsent_train_text_bert_all_repr[text] for text in truncated_dsent_train[\"sentence\"].values}\n",
    "#     truncated_bakeoff_dev_text_bert_all_repr = {text: bakeoff_dev_text_bert_all_repr[text] for text in bakeoff_dev[\"sentence\"].values}\n",
    "#     truncated_sst_dev_text_bert_all_repr = {text: sst_dev_text_bert_all_repr[text] for text in sst_dev[\"sentence\"].values}\n",
    "#     sst_test = sst.test_reader(SST_HOME)\n",
    "#     truncated_sst_test_text_bert_all_repr = {text: sst_test_text_bert_all_repr[text] for text in sst_test[\"sentence\"].values}\n",
    "#     bakeoff_test = sst.bakeoff_test_reader(SST_HOME)\n",
    "#     truncated_bakeoff_test_text_bert_all_repr = {text: bakeoff_test_text_bert_all_repr[text] for text in bakeoff_test[\"sentence\"].values}"
   ],
   "execution_count": 134,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H9fdxyS7jXAG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631493081080,
     "user_tz": -330,
     "elapsed": 7575,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# truncated_full_text_bert_all_repr = {}\n",
    "# truncated_full_text_bert_all_repr = {**truncated_full_text_bert_all_repr, **truncated_sst_train_bert_all_repr, **truncated_sst_test_text_bert_all_repr, **truncated_sst_dev_text_bert_all_repr, **truncated_bakeoff_dev_text_bert_all_repr, **truncated_bakeoff_test_text_bert_all_repr, **truncated_dsent_train_bert_all_repr}\n",
    "# save_obj(truncated_full_text_bert_all_repr, 'truncated_full_text_bert_all_repr')"
   ],
   "execution_count": 149,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K5lImfqq960J",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631493507146,
     "user_tz": -330,
     "elapsed": 2370,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    truncated_full_text_bert_all_repr = load_obj('truncated_full_text_bert_all_repr')\n",
    "\n",
    "    def bert_all_phi(text):\n",
    "        truncated_full_text_bert_all_repr[text]\n",
    "\n",
    "    def fit_rnn_bert_based_seq(X, y):\n",
    "        mod = TorchRNNClassifier(\n",
    "            vocab=[],\n",
    "            hidden_dim=256,\n",
    "            early_stopping=True,\n",
    "            bidirectional=True,\n",
    "            use_embedding=False)\n",
    "        mod.fit(X, y)\n",
    "        return mod"
   ],
   "execution_count": 152,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ROzxid_2EIQd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631494784105,
     "user_tz": -330,
     "elapsed": 375,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# TODO(schowdhary): Complete sequential BERT embedding based RNN model\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:   \n",
    "#     %%time\n",
    "#     rnn_bert_based_seq_bert_all_phi_experiment = sst.experiment(\n",
    "#         [sst_train, truncated_dsent_train],\n",
    "#         bert_all_phi,\n",
    "#         fit_rnn_bert_based_seq,\n",
    "#         assess_dataframes=[sst_dev, bakeoff_dev],\n",
    "#         vectorize=False)"
   ],
   "execution_count": 160,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2F1bmie5hZeB"
   },
   "source": [
    "#### 5. Combining the best models till now through an ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLMuhgev8qCO"
   },
   "source": [
    "**_We define a Hybrid-Custom Model that weighted-averages on the probability matrix of the chosen top performing models from the above._** This object tries to\n",
    "include as few interfaces as possible to just make it work with the user code."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z5o0GElshgUa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631508099825,
     "user_tz": -330,
     "elapsed": 366,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ: \n",
    "    from sklearn.metrics import classification_report\n",
    "    class CustomClassifier:\n",
    "        def __init__(self, exp_list, model_weights):\n",
    "            self.exp_list = exp_list\n",
    "            self.model_weights = model_weights\n",
    "            self.aggr_proba = [0.] * 3\n",
    "            # WARNING: Dont change the order here, as the base class of the models\n",
    "            # number the classes internally this way only\n",
    "            self.label = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "            assert np.sum(model_weights) == 1\n",
    "            assert len(exp_list) == len(model_weights)\n",
    "\n",
    "        def predict_one(self, text):\n",
    "            exp_idx = 0\n",
    "            self.aggr_proba = [0.] *3\n",
    "            for exp in self.exp_list:\n",
    "                if exp['train_dataset']['vectorizer'] is not None:\n",
    "\n",
    "                    # print(\"EXP: \", str(exp_idx) , \" is vectorizer based\")\n",
    "                    feats = [exp['phi'](text)]\n",
    "                    X = exp['train_dataset']['vectorizer'].transform(feats)\n",
    "\n",
    "                else:\n",
    "                    # print(\"EXP: \", str(exp_idx), \" is NOT vectorizer based\")\n",
    "\n",
    "                    X = [exp['phi'](text)]\n",
    "\n",
    "                pred_proba = exp['model'].predict_proba(X)[0]\n",
    "\n",
    "                pred_proba_red = pred_proba * self.model_weights[exp_idx]\n",
    "\n",
    "                # print(\"EXP: \", str(exp_idx), \" is predicting \", pred_proba)\n",
    "                # print(\"EXP: \", str(exp_idx), \" is predicting nord \", pred_proba_red)\n",
    "\n",
    "                self.aggr_proba = [sum(x) for x in zip(self.aggr_proba, pred_proba_red)]\n",
    "\n",
    "                # print(\"EXP: \", str(exp_idx), \" is predicting aggr \", self.aggr_proba)\n",
    "\n",
    "                exp_idx+=1\n",
    "\n",
    "            aggr_proba_arr = np.array(self.aggr_proba)\n",
    "            test_pred = [self.label[aggr_proba_arr.argmax(axis=0)]]\n",
    "\n",
    "            return test_pred[0]\n",
    "    \n",
    "    def confusion_result(custom_classifier):\n",
    "        sst_dev = sst.dev_reader(SST_HOME)\n",
    "        bakeoff_dev = sst.bakeoff_dev_reader(SST_HOME)\n",
    "        dev_sets = [sst_dev, bakeoff_dev]\n",
    "\n",
    "        for dev_set in dev_sets:\n",
    "            dev_set_y_dev = dev_set['label'].values\n",
    "            dev_set_y_pred = [custom_classifier.predict_one(text) for text in dev_set['sentence'].values]\n",
    "            print(classification_report(dev_set_y_dev, dev_set_y_pred, digits=3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": 204,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7WZTiyJsHeg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631508189432,
     "user_tz": -330,
     "elapsed": 62853,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "76a55c15-f657-4717-b593-6e9a41db6916"
   },
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ: \n",
    "    custom_classifier = CustomClassifier([optim_bert_classifier_experiment, custom_nn_bert_based_bert_repr_phi_experiment, rnn_bert_based_tweet_token_phi_experiment], [0.6, 0.2, 0.2])\n",
    "    confusion_result(custom_classifier)"
   ],
   "execution_count": 206,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.809     0.811     0.810       428\n",
      "     neutral      0.509     0.354     0.418       229\n",
      "    positive      0.772     0.892     0.828       444\n",
      "\n",
      "    accuracy                          0.748      1101\n",
      "   macro avg      0.697     0.685     0.685      1101\n",
      "weighted avg      0.732     0.748     0.735      1101\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.747     0.766     0.756       565\n",
      "     neutral      0.807     0.822     0.815      1019\n",
      "    positive      0.828     0.792     0.809       777\n",
      "\n",
      "    accuracy                          0.799      2361\n",
      "   macro avg      0.794     0.793     0.793      2361\n",
      "weighted avg      0.799     0.799     0.799      2361\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RTnAKOd3tJe"
   },
   "source": [
    "Maximum records:\n",
    "(nn_bert, rnn_bert) -> (0.5, 0.5) -> 0.683\n",
    "\n",
    "-> (0.4, 0.6) -> 0.6825\n",
    "\n",
    "-> (0.6, 0.4) -> 0.683\n",
    "\n",
    "-> (0.7, 0.3) -> 0.6815\n",
    "\n",
    "So for this combination, the best combination is (0.5, 0.5)\n",
    "\n",
    "(optim_bert, nn_bert, rnn_bert) -> (1, 0, 0) -> 0.7355\n",
    "\n",
    "**_->(0.6, 0.2, 0.2) -> 0.739_**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yOM1mB6JyZcr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631481283351,
     "user_tz": -330,
     "elapsed": 377,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    }
   },
   "source": [
    "# # TESTER CALL on predict_one to check if it matches original answers\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ: \n",
    "#     def predict_one(text):\n",
    "#         # Singleton list of feature dicts:\n",
    "#         X = [custom_nn_bert_based_bert_repr_phi_experiment['phi'](text)]\n",
    "\n",
    "#         # Standard sklearn `predict` step:\n",
    "#         preds = custom_nn_bert_based_bert_repr_phi_experiment['model'].predict(X)\n",
    "#         # Be sure to return the only member of the predictions,\n",
    "#         # rather than the singleton list:\n",
    "#         return preds[0]\n",
    "\n",
    "#     dev_sets = [sst_dev, bakeoff_dev]\n",
    "\n",
    "#     for dev_set in dev_sets:\n",
    "#         dev_set_y_dev = dev_set['label'].values\n",
    "#         dev_set_y_pred = [predict_one(text) for text in dev_set['sentence'].values]\n",
    "\n",
    "#         # print(dev_set_y_dev[0:10])\n",
    "#         # print(dev_set_y_pred[0:10])\n",
    "#         print(classification_report(dev_set_y_dev, dev_set_y_pred, digits=3))\n",
    "    "
   ],
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDUU9BLy-aat"
   },
   "source": [
    "#### 6. Error Analysis on weaker of the chosen models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQwPBVRw-epL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631500332295,
     "user_tz": -330,
     "elapsed": 452,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "a58a6adf-8aa2-4993-80aa-9116b6e44c24"
   },
   "source": [
    "# between experiments custom_nn_bert_based_bert_repr_phi_experiment & rnn_bert_based_tweet_token_phi_experiment\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    analysis_custom_nn_bert_based_bert_repr_phi_experiment = \\\n",
    "    find_errors(custom_nn_bert_based_bert_repr_phi_experiment)\n",
    "    analysis_rnn_bert_based_tweet_token_phi_experiment = \\\n",
    "    find_errors(rnn_bert_based_tweet_token_phi_experiment)\n",
    "\n",
    "    analysis = analysis_custom_nn_bert_based_bert_repr_phi_experiment.merge(\n",
    "    analysis_rnn_bert_based_tweet_token_phi_experiment, left_on='raw_examples',\n",
    "     right_on='raw_examples')\n",
    "\n",
    "    analysis = analysis.drop('gold_y', axis=1).rename(columns={'gold_x': 'gold'})\n",
    "\n",
    "    # Examples where the 1st is correct, 2nd is not,\n",
    "    # and the gold label is 'neutral'\n",
    "\n",
    "    error_group = analysis[\n",
    "        (analysis['predicted_x'] == analysis['gold'])\n",
    "        &\n",
    "        (analysis['predicted_y'] != analysis['gold'])\n",
    "        &\n",
    "        (analysis['gold'] == 'positive')\n",
    "    ]\n",
    "\n",
    "    print(\"Error group shape: \\n\", error_group.shape[0])\n",
    "\n",
    "    for ex in error_group['raw_examples'].sample(5, random_state=1):\n",
    "        print(\"=\"*70)\n",
    "        print(ex)"
   ],
   "execution_count": 187,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error group shape: \n",
      " 99\n",
      "======================================================================\n",
      "I ordered medium and it actually came out medium.\n",
      "======================================================================\n",
      "It's going to take quite a few visits to try everything that called out to me on the menu.\n",
      "======================================================================\n",
      "` De Niro ... is a veritable source of sincere passion that this Hollywood contrivance orbits around . '\n",
      "======================================================================\n",
      "It was like a choreographied dance...haven't seen that kind of service since I was in Europe!\n",
      "======================================================================\n",
      "My mom and I wanted to try this restaurant out, so I decided it would be a great place to go to celebrate Mother's Day.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FK9bPSFP_7EL"
   },
   "source": [
    "**_Neutral classifications for both these models are poor. So it is good to see where would the two models differ in their idea for \"neutral\" even when both of them are bad at it._**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twMNEWE5A4JJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631500779550,
     "user_tz": -330,
     "elapsed": 372,
     "user": {
      "displayName": "Shubham Chowdhary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgFkFw1pKwpL_S-zFEuR17zOZk_I_CGJ-d72aCpmg=s64",
      "userId": "09510905510812321280"
     }
    },
    "outputId": "3a51354c-2acc-4f9c-9b16-77e1e565638e"
   },
   "source": [
    "# McNemar's Test\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    m = utils.mcnemar(\n",
    "        custom_nn_bert_based_bert_repr_phi_experiment['assess_datasets'][0]['y'],\n",
    "        custom_nn_bert_based_bert_repr_phi_experiment['predictions'][0],\n",
    "        rnn_bert_based_tweet_token_phi_experiment['predictions'][0])\n",
    "    \n",
    "    p = \"p < 0.0001\" if m[1] < 0.0001 else m[1]\n",
    "\n",
    "    print(\"McNemar's test: {0:0.02f} ({1:})\".format(m[0], p))"
   ],
   "execution_count": 188,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "McNemar's test: 0.15 (0.6967274236606604)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKTgPnSlE4qL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 7. Test Set Score ~0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Future Work/Limitations\n",
    "1. Extend the above original system for 5-class data-labels\n",
    "2. The SST3 dataset used in this experiment has somewhat unbalanced examples across the 3 labels. To be precise, some examples that are just simple facts, are labelled \"positive\"/\"negative\" based on prevalent human-emotions making \"neutral\" label extremely under-represented. Hence the \"neutral\" sentiment detection performance was relatively poor.\n",
    "3. Moreover, the 3-class datasets we used are a direct translation from 5-star/class review corpora, where (1,2) are \"negative\", 3 is neutral, and (4,5) are \"positive\". But in reality, a product/service/movie rated 3 \"stars\" might not always be regarded \"neutral\" and might still reflect some positive sentiment/degree of happiness on the part of the review maker. This kind of subjectivity is not modelled here.\n",
    "4. Future work can try to improve on a cross-dataset sentiment perception. If a model is trained to detect sentiments from only a movie review dataset, it should still be able to detect sentiments \"well-enough\" for a product review, for example, by capturing basic hidden representations of \"positive\"/\"negative\"/\"neutral\" feelings.\n",
    "5. Since the \"neutral\" labels had poor performance on test set, we might look into a system that first tries to classify reviews as facts/non-facts. This classification might help augmenting a correct classification between \"neutral\" and other extreme classes.\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### References\n",
    "\n",
    "1. [Prof. Chris Potts' Implementation on Negative Tokenizing](http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py)\n",
    "2. [Prof. Chris Potts' NLP Research Architecture](https://github.com/cgpotts/cs224u)\n",
    "3. [DynaSent DataSet](https://github.com/cgpotts/dynasent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}